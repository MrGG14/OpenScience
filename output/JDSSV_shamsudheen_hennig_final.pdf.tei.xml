<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Should We Test the Model Assumptions Before Running a Model-based Test?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Iqbal</forename><surname>Shamsudheen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Hennig</surname></persName>
						</author>
						<title level="a" type="main">Should We Test the Model Assumptions Before Running a Model-based Test?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEA8EB3AE4929FE4D6C9B219A2B5DA75</idno>
					<idno type="DOI">10.52933/jdssv.v3i3.73</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-05-21T17:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>misspecification testing</term>
					<term>goodness of fit</term>
					<term>combined procedure</term>
					<term>two-stage testing</term>
					<term>misspecification paradox</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Statistical methods are based on model assumptions, and it is statistical folklore that a method's model assumptions should be checked before applying it. This can be formally done by running one or more misspecification tests of model assumptions before running a method that requires these assumptions; here we focus on model-based tests. A combined test procedure can be defined by specifying a protocol in which first model assumptions are tested and then, conditionally on the outcome, a test is run that requires or does not require the tested assumptions. Although such an approach is often taken in practice, much of the literature that investigated this is surprisingly critical of it. Our aim is to explore conditions under which model checking is advisable or not advisable. For this, we review results regarding such "combined procedures" in the literature, we review and discuss controversial views on the role of model checking in statistics including the use of visualisation, and we present a general setup in which we can show that preliminary model checking is advantageous, which implies conditions for making model checking worthwhile.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Statistical methods are based on model assumptions, and it is statistical folklore that a method's model assumptions should be checked before applying it. Some authors believe that the invalidity of model assumptions and the failure to check them is at least partly to blame for what is currently discussed as "replication crisis" <ref type="bibr" target="#b70">(Mayo (2018)</ref>), and indeed model checking is ignored in much applied work <ref type="bibr" target="#b57">(Keselman et al. (1998)</ref>; <ref type="bibr">Strasak et al. (2007a,b)</ref>; <ref type="bibr" target="#b116">Wu et al. (2011)</ref>; <ref type="bibr" target="#b101">Sridharan and Gowri (2015)</ref>; <ref type="bibr" target="#b78">Nour-Eldein (2016)</ref>). Yet there is surprisingly little agreement in the literature about how to check the models. As will be seen later, several authors who investigated the statistical characteristics of running model checks before applying a model-based method, come to negative conclusions. So is it sound advice to check model assumptions first? If so, are model misspecification tests a good tool for doing this? Here we present a comprehensive discussion of the issue, including a survey of the literature in which this is investigated.</p><p>The amount of literature on certain specific problems that belong to this scope is quite large and we do not attempt to review it exhaustively. We restrict our focus to the problem of two-stage testing, i.e., hypothesis testing conditionally on the result of preliminary tests of model assumptions. More work exists on estimation after preliminary testing. For overviews see <ref type="bibr" target="#b6">Bancroft and Han (1977)</ref>; <ref type="bibr" target="#b35">Giles and Giles (1993)</ref>; <ref type="bibr" target="#b13">Chatfield (1995)</ref>; <ref type="bibr" target="#b89">Saleh (2006)</ref>. Almost all existing work focuses on analysing specific preliminary tests and specific conditional inference; here a more general view is provided.</p><p>To fix terminology, we assume a situation in which a researcher is interested in using a "main test" for testing a main hypothesis that is of substantial interest. There is a "model-based constrained (MC) test" involving certain model assumptions available for this. We will call "misspecification (MS) test" a test with the null hypothesis that a certain model assumption holds. We assume that this is not of primary interest, but rather only done in order to assess the validity of the model-based test, which is only carried out in case the MS test does not reject (or "passes") the model assumption. In case the MS test rejects the model assumption, there may or may not be an "alternative unconstrained (AU) test" that the researcher applies, which does not rely on the rejected model assumption, in order to test the main hypothesis. A "combined procedure" consists of the complete decision rule involving the MS test, MC test, and AU test (if specified); see Figure <ref type="figure" target="#fig_0">1</ref>. More complex combined procedures can also be defined, in which more than one model assumption is tested, and more than one AU test could be considered, depending on which specific model assumption is rejected.</p><p>As an example consider a situation in which a psychiatrist wants to find out whether a new therapy is better than a placebo based on continuous measurements of improvement on two groups of patients; one group treated with the new therapy, the other with the placebo. The researcher may want to apply a two-sample t-test, which assumes normality (MC test). Normality can be tested, e.g., by a Shapiro-Wilk test (MS test) in both groups, and in case normality is rejected, the researcher may decide to apply a Wilcoxon-Mann-Whitney (WMW) rank test (AU test) that does not rely on normality. Such a procedure is, for example, applied in <ref type="bibr" target="#b52">Holman and Myers (2005)</ref>; <ref type="bibr" target="#b62">Kokosinska et al. (2018)</ref>, and endorsed in some textbooks, see, e.g., Fig. <ref type="figure">8</ref>.5 in <ref type="bibr" target="#b19">Dowdy et al. (2004)</ref>. The following issues occur:  • The two-sample t-test has further assumptions apart from normality, namely, that the data within each group are independently identically generated (i.i.d.), the groups are independent, and the variances are homogeneous. There are also assumptions regarding external validity, such as the sample being representative for the population of interest, and the measurements being valid. Neither is the WMW test assumption free, even though it does not assume normality. Using only a single MS test, not all of these assumptions are checked, and all three tests, MS, MC, and AU may be invalidated, e.g., by problems with the i.i.d. assumption. Using more than one MS test for checking model assumptions (e.g., using the Shapiro-Wilk test as a first MS test of normality and the F-test as a second MS test of homogeneity of variances) before running the MC test may be recommended, and conditionally of the outcome of the MS tests, more than one AU test, see above. Investigating combined procedures involving a single MS and AU test, as is mostly done in the literature and in the present work as well, is a simplification, and can be seen as analysing the building blocks of a more complex strategy that may be applied in reality.</p><p>• The two-sample t-test tests the null hypothesis H 0 : µ 1 = µ 2 against H 1 : µ 1 ̸ = µ 2 (or larger, or smaller), where µ 1 and µ 2 are the means of the two normal distributions within the two groups. H 0 and H 1 are defined within the normal model, and more generally, H 0 and H 1 of the MC test are defined within the assumed model. H 0 and H 1 tested by the AU test will not in general be equivalent, so there needs to be an explicit definition of the hypotheses tested by a procedure that depending on the result of the MS test will either run the MC or the AU test. In the example, in case that the variances are indeed homogeneous, the H 0 and H 1 tested by the t-test are a special case of H 0 and H 1 tested by the WMW test, namely that the two within-groups distributions are equal (H 0 ) or that one is stochastically larger or smaller than the other (H 1 ). See <ref type="bibr" target="#b25">Fay and Proschan (2010)</ref> for a discussion of different "perspectives" of what the WMW-and t-test actually test. The combined procedure delivers a test of these more general H 0 and H 1 , which sometimes may not be so easy to formalise. The key issue is how the scientific research question (whether the new therapy is equivalent to a placebo) translates into the specific model assumed by the MC test and the more general model assumed by the AU test.</p><p>The AU test may rely on fewer assumptions by being nonparametric as above, or by being based on a more general parametric model (such as involving an auto-regressive component in case of violation of independence). It does not necessarily have to be based on more general assumptions than the MC test, it could also, for example, apply the original model with a transformed variable.</p><p>The central concept of the present work is that the question whether it is advisable to check the model assumptions first, can be addressed by an analysis of the performance characteristics of combined procedures, i.e., type 1 and type 2 error probabilities (of rejecting a true null hypothesis, and of not rejecting the null in case the alternative is true; this is one minus the power) of the main test conditional on the result of the MS test, looking at both situations in which the model assumptions of the MC test are fulfilled, and where they are violated, potentially in various different ways, not necessarily even fulfilling the assumptions of the AU test. The issue of interest here is whether the performance characteristics of the combined procedure are good enough to recommend it, compared to running either the MC or the AU test unconditionally. We review existing results of this kind (all of which concern specific choices of MS, AU, and MC test), we review and discuss the concept in the context of general model assumption checking including some controversial views of it, we present a new theoretical result that has some implications for how to do MS testing, and we touch on some implications for practice. It is not the aim of the present work to make recommendations for specific problems; we rather outline a general attitude and guidelines for how to deal with model assumption testing. We will also comment on informal (visual) model checking.</p><p>The binary nature of statistical tests has recently been controversially discussed (Wasserstein and Lazar ( <ref type="formula">2016</ref>)). Our focus on type 1 and type 2 error probabilities is not meant to advocate simplistic "accept/reject" decisions in science, but rather to allow for a transparent analysis to improve the understanding of the procedures. Note though that the decision to proceed with a certain model-based method or not is essentially binary (potentially with more than two branches), so that binary decisions cannot be entirely avoided.</p><p>It is well known, going back to <ref type="bibr" target="#b4">Bancroft (1944)</ref>, that the performance characteristics of a combined procedure differ in general from the characteristics of the MC test run unconditionally, even if the model assumptions of the MC test are fulfilled. This can be seen as a special case of data-dependent analysis, called "garden of forking paths" by <ref type="bibr" target="#b33">Gelman and Loken (2014)</ref>. They suggest that such analyses contribute to the fact that "reported statistically significant claims in scientific publications are routinely mistaken", particularly if the researchers choose freely, conditionally on test results, which of potentially many outcomes they report. The preliminary definition of combined procedures can serve as some kind of pre-registration to protect against leaving too many degrees of freedom to the researcher, and it allows to analyse the implications of what is done.</p><p>We generally assume that the MS test is carried out on the same data as the main test. Some of the issues discussed here can be avoided by checking the model on independent data, however such data may not be available. See <ref type="bibr" target="#b13">Chatfield (1995)</ref> for a discussion of obtaining the "independent" data by splitting the available data set, which will result in less data used for the main test, and therefore in loss of power. In any case it would leave open the question whether the data used for MS testing are really independent of the data used for the main test, and whether they do really follow the same model. If possible, this is however a valuable option.</p><p>The situation is confusing for the user in the sense that checking model assumptions is recommended in many places (e.g., <ref type="bibr" target="#b98">Spanos (1999)</ref>; <ref type="bibr" target="#b14">Cox (2006)</ref>; <ref type="bibr" target="#b56">Kass et al. (2016)</ref>), but an exact formal specification of how to do this in any given situation is hardly ever given. Tests are routinely used in applied research to decide about model assumptions in all kinds of setups, often for deciding how to proceed further (e.g., <ref type="bibr" target="#b29">Gambichler et al. (2002)</ref>  <ref type="bibr" target="#b81">(Pitman (1937)</ref>) run unconditionally.</p><p>Data have been generated from the normal distribution N (µ i , 1), a t 3 -distribution shifted by µ i (here the variance exists and the Central Limit Theorem (CLT) applies, so that the t-test is asymptotically valid), an exponential distribution with mean µ i , and a skew normal distribution with skewness parameter α = 3 and the other parameters chosen so that the variance is 1 and the expected value is µ i . For the main null hypothesis we used µ 1 = µ 2 = 1; for the main alternative µ 1 = 1, µ 2 = 2. We ran 100,000 replicates. Based on the 100,000 simulation runs, p-values for one-sided binomial tests of the true type 1 error probability being 0.05 are between 0.01 and 0.05 for the combined procedure in the normal and t 3 -case, and &lt; 0.001 in the skew normal case; differences between powers interpreted above are all highly significant. Combined procedure and permutation test do not have a significantly better power than the t-test for the normal distribution, and neither does the combined procedure compared to the WMW test for the exponential distribution.</p><p>The example shows that</p><p>• even if model assumptions are clearly violated, an MC test may be better than the AU test or the combined procedure (exponential distribution);</p><p>• often (normal, t 3 , skew normal) the combined procedure is beneficial in the sense that its type 2 error probability is close to the better one of the MC and AU test, but this does not always work (exponential);</p><p>• the combined procedure may even reach a better power than both the MC and AU test (skew normal), but it may also happen that its type 1 error probability is higher than the nominal 0.05 (normal, t 3 , skew normal) -this is different from the MC and AU test, which both respect the nominal level throughout this study;</p><p>• the "distribution free" methods WMW and permutation test do not perform uniformly well over all distributions.  <ref type="bibr">(Albers et al. (2000a)</ref> present theory that in the situation of Section 5.1 involves bounding the type 1 error probability at α(1 + ϵ) with specified small ϵ, where α is the nominal level). In Example 1, this cannot be said for the combined procedure compared with WMW and permutation in the skew normal case, but it may look more attractive compared with WMW in the normal case, and with permutation in the t 3 case. In general, both type 1 and type 2 error probabilities should be considered; we will not make assumptions here regarding the amount of tolerable anticonservativity, but rather note that this issue often plays a role when comparing test performances.</p><p>Given the difficulty to define a convincing formal approach, it is not surprising that informal approaches for model checking are often used. Many researchers do informal model checking (e.g., visual, such as looking at boxplots for diagnosing skewness and outliers, or using regression residual plots to diagnose heteroscedasticity or nonlinearity), and they may only decide how to proceed knowing the outcome of the model check (be it formal or informal), rather than using a combined procedure that was well defined in advance. In fact, searching the web for terms such as "checking model assumptions" finds far more recommendations to use graphical model assessment than formal MS tests. An obvious advantage of such an approach is that the researcher can see more specifically suspicious features of the data, often suggesting ways to deal with them such as transformations. This may work well, however it depends on the researcher who may not necessarily be competent enough to do this better than a formal procedure, and it has the big disadvantage that it cannot be formally investigated and replicated by other researchers, which would certainly be desirable. See <ref type="bibr" target="#b93">Schmidt and Finan (2018)</ref> for a critical assessment of using ad hoc transformations in regression for improving normality. Only if the way in which the researcher makes a visual decision is formalised, this can be analysed as another combined procedure.</p><p>Apart from the example, we will consider specific investigations only as far as already covered in the literature. In Section 2, we present our general perspective of model assumption checking. Section 3 formally introduces a combined procedure in which an MS test is used to decide between an MC and an AU main test. Section 4 reviews the controversial discussion of the role of model checking and testing in statistics. Section 5 runs through the literature that investigated the impact of misspecification testing and the performance of combined procedures in various scenarios. In Section 6, we present a new result that formalises a situation in which a combined procedure can be better than both the MC and the AU test. Section 7 concludes the paper and gives some conditions for model assumption checking to work well, which may stimulate further research and development of model checking procedures that are better than existing ones at finding those issues with the model assumptions that matter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A General Perspective on Model Assumption Checking</head><p>Our view of model assumptions and assumption checking is based on the idea that models are thought constructs that necessarily deviate from reality but can be helpful devices to understand it <ref type="bibr" target="#b48">(Hennig (2010)</ref>, with elaboration for frequentist and Bayesian probability models in Section 5 of <ref type="bibr" target="#b32">Gelman and Hennig (2017)</ref>). Models can be used to show that certain procedures are good or even optimal in a certain sense, such as the Neyman-Pearson Lemma for tests; the WMW-test is not normally justified by an optimality result (although it is optimal in a very specific situation, see Example 13.14 of van der Vaart (1998)), but rather by results warranting the validity of the level and the unbiasedness against certain alternatives, see <ref type="bibr" target="#b25">Fay and Proschan (2010)</ref>; unbiasedness means that the rejection probability is always ≤ α (nominal level) throughout the H 0 , and ≥ α throughout the H 1 . The term "model assumption" generally refers to the existence of such results, meaning that a method has a certain guaranteed quality if the model assumptions hold.</p><p>We do not think that it is ever appropriate to state that any model is "really true" or any model assumption "really holds". The best that can be said is that it may be appropriate and useful to treat reality as if a certain model were true, acknowledging that this is always an idealisation. A test generally checks whether observed data are compatible with a model in a certain respect, which is defined by the test statistic. All data are compatible with many models; there are always alternatives to any assumed model that cannot be ruled out by the data, such as non-identical distributions that allow a different parameter choice for each observation or certain dependence structures <ref type="bibr" target="#b49">(Hennig (2023)</ref>).</p><p>Starting from the classical work of <ref type="bibr" target="#b3">Bahadur and Savage (1956)</ref>, there are results on the impossibility to identify from arbitrarily large data certain features of general families of distributions such as their means, or bounds on the density <ref type="bibr" target="#b18">(Donoho (1988)</ref>). This means that it is ultimately impossible to make sure that model assumptions precisely or even only approximately hold.</p><p>In order to increase our understanding of the performance of a statistical procedure, it is instructive to not only look at its results in situations in which the model assumptions are fulfilled, but also to explore it on models for which they are violated, but chosen so that if they were true, applying the procedure of interest still seems realistic. Such an approach is taken in Example 1, the literature discussed in Section 5, as well as in much literature on robust statistics, the latter mostly interested in worst case considerations (e.g., <ref type="bibr" target="#b42">Hampel et al. (1986)</ref>). According to <ref type="bibr" target="#b106">Tukey (1997)</ref>, confronting a number of procedures with a "bouquet of challenges", i.e., data generated in various ways as in Example 1, is a key guideline for data analysis in the absence of knowledge of a "true model".</p><p>The problem that a procedure is meant to solve is often defined in terms of the assumed model. If other models are considered for data generation, an analogous problem has to be defined for those other models, which may not always be unique. A suitable way to think about this is that there is an informal scientific hypothesis and alternative of interest (such as "no difference between treatments" vs. "treatment A is better") that can be translated into various probability models, potentially in more than one way (e.g., "treatment A is better" may in a nonparametric setting translate into "treatment A's distribution is stochastically larger", or "treatment A's distribution is a positive shift of treatment B's distribution", or "the expected outcome value of treatment A is larger"). Such a "translation" is required in order to investigate error probabilities on other than the originally assumed models, and to assess whether these are still satisfactory.</p><p>The problem of checking model assumptions is often wrongly framed as "checking whether the model assumptions hold". In reality they will not hold precisely anyway, but a method may still perform well in that case, and the model assumption may not even be required to hold "approximately" (see the exponential case in Example 1). But there are certain violations of the model assumptions that have the potential to mislead the results in the sense of giving a wrong assessment of the underlying scientific hypothesis with high probability (e.g., for t 3 in Example 1 the probability is rather large that the t-test will conclude that there is insufficient evidence against the H 0 if data were in fact generated from the H 1 where other procedures can find such evidence). "Checking the model assumptions" should rule such situations out as far as possible. This implies that model assumption checking needs to distinguish problematic violations from unproblematic ones, rather than distinguishing a true model from any wrong one. We think that some assumption checking does not work very well (see Section 5) because it tries to solve the latter problem instead of the former.</p><p>Model assumption checking and choosing a subsequent method of inference conditionally on it, i.e., combined procedures, may help if done right, but may not help or even hurt if done wrong. Investigation of how well these procedures work in all kinds of relevant situations is therefore of interest. This is however hard, because the performance depends on all kinds of details, including the choice of MS, MC, and AU test, and particularly the models on which the procedures are assessed. Unfortunately, assuming that data dependent decisions are not made before the combined procedure is applied, the user may have little information about what distribution to expect, so that a wide range of possibilities is conceivable, and different authors may well come to different conclusions regarding the same problem (see the Introduction) based on different considered alternatives to the assumed model. This makes the worst case considerations as in robust statistics attractive, but looking at a range of specific choices will give a more comprehensive picture. Given that certain violations of assumptions cannot be detected from the data alone, knowledge of the context (such as sampling schemes, measurement procedures, previous studies) should always be used to highlight potential issues on top of what can be diagnosed from the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Combined Procedures</head><p>The general setup is as follows. Given is a statistical model</p><formula xml:id="formula_0">M Θ = {P θ , θ ∈ Θ} ⊂ M,</formula><p>where P θ , θ ∈ Θ are distributions over a space of interest, indexed by a parameter θ. M Θ is written here as a parametric model, but we are not restrictive about the nature of Θ. M Θ may even be the set of all i.i.d. models for n observations, in which case Θ would be very large. However, in the literature, M Θ is usually a standard parametric model with Θ ⊆ R m for some m. There is a model M containing distributions that do not require one or more assumptions implied by the definition of M Θ , but for data from the same space.</p><p>Given some data z, we want to test a parametric null hypothesis θ ∈ Θ 0 , which has some suitably chosen "extension" M * ⊂ M so that M * ∩ M Θ = M Θ 0 , against the alternative θ ̸ ∈ Θ 0 corresponding to M \ M * in the bigger model. In some cases (for example, when applying the original model to transformed variables) M may not contain M Θ , and M * ⊂ M then needs to be some kind of "translation" of the research hypothesis M Θ 0 into M , the choice of which should be context guided and may or may not be trivial (e.g., equal group means for normals may be chosen to translate into equal medians rather than means when looking at distributions that can produce gross outliers with a certain non-vanishing probability).</p><p>In the simplest case, there are three tests involved, namely the MS test Φ M S , the MC test Φ M C and the AU test Φ AU . Tests can take values 0 or 1, where 1 means rejection of the null hypothesis. Let α M S be the level of Φ M S , i.e.,</p><formula xml:id="formula_1">Q(Φ M S (z) = 1) ≤ α M S for all Q ∈ M Θ .</formula><p>Let α be the level of the two main tests, i.e., P θ (Φ M C (z) = 1) ≤ α for all P θ , θ ∈ Θ 0 and Q(Φ AU (z) = 1) ≤ α for all Q ∈ M * . To keep things general, for now we do not assume that type 1 error probabilities are uniformly equal to α M S , α, respectively, and neither do we assume tests to be unbiased (which may not be realistic considering a big nonparametric M ).</p><p>The combined test is defined as</p><formula xml:id="formula_2">Φ C (z) = Φ M C (z) if Φ M S (z) = 0, Φ AU (z) if Φ M S (z) = 1.</formula><p>This allows to analyse the characteristics of Φ C , particularly its effective level (which is not guaranteed to be ≤ α) and power under P θ , or under distributions from M * or M \ M * . Theoretical results are often hard to obtain without making restrictive assumptions, although some exist, see Sections 5.1 and 5.4. At the very least, simulations are possible picking specific P θ or Q ∈ M , and in many cases results may generalise to some extent because of invariance properties of model and test.</p><p>Also of potential interest are P θ (Φ C (z) = 1|Φ M S (z) = 0), i.e., the type 1 error probability under M Θ 0 or the power under M Θ in case the model was in fact passed by the MS test,</p><formula xml:id="formula_3">Q (Φ C (z) = 1|Φ M S (z) = 0) for Q ∈ M \ M Θ , i.e.</formula><p>, the situation that the model M Θ is in fact violated but was passed by the MS test, and whether Φ C can compete with Φ AU in case that Φ M S (z) = 1 (M Θ rejected). These are investigated in some of the literature, see below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Controversial Views of Model Checking</head><p>The necessity of model checking has been stressed by many statisticians for a long time, and this is what students of statistics are often taught. <ref type="bibr" target="#b27">Fisher (1922)</ref> stated:</p><p>For empirical as the specification of the hypothetical population may be, this empiricism is cleared of its dangers if we can apply a rigorous and objective test of the adequacy with which the proposed population represents the whole of the available facts. <ref type="bibr" target="#b77">Neyman (1952)</ref> outlined the construction of a mathematical model, and emphasised checking the assumptions of the model by observation. <ref type="bibr" target="#b80">Pearson (1900)</ref> introduced the goodness of fit chi-square test, which was used by Fisher to test model assumptions. The term "misspecification test" was coined as late as <ref type="bibr" target="#b26">Fisher (1961)</ref> for the selection of exogenous variables in economic models. <ref type="bibr" target="#b98">Spanos (1999)</ref> used the term extensively. <ref type="bibr" target="#b10">Box (1980)</ref> emphasised the use of both MS tests and informal model diagnostics for Bayesian modelling. See <ref type="bibr" target="#b100">Spanos (2018)</ref> for the history and an exhaustive discussion of the use of MS tests.</p><p>At first sight, model checking seems essential for two reasons. Firstly, statistical methods that a practitioner may want to use are often justified by theoretical results that require model assumptions. Secondly, it is easy to construct examples for the breakdown of methods in case model assumptions are violated in critical ways (e.g., inference based on the arithmetic mean, optimal under the assumption of normality, will break down for data generated from a Cauchy distribution).</p><p>Regarding the foundations of statistics, checking of the model assumptions plays a crucial role in Mayo (2018)'s philosophy of "severe testing", in which frequentist significance tests are portrayed as major tools for subjecting scientific hypotheses to tests that they could be expected to fail in case they were wrong; and evidence in favour of such hypotheses can only be claimed in case they survive such severe probing. Mayo acknowledged that significance tests can be misleading in case the model assumptions are violated, but model assumptions themselves can be tested, and this offers some protection. A problem with this is that to our knowledge there are no results regarding the severity of MS tests, meaning that it is unclear to what extent a non-rejection of model assumptions implies that they are indeed not violated in ways that endanger the validity of the main test.</p><p>A problem with preliminary model checking is that the theory of the model-based methods usually relies on the implicit assumption that there is no data-dependent preselection or pre-processing. A check of the model assumptions is a form of pre-selection. This is largely ignored but occasionally mentioned in the literature. <ref type="bibr" target="#b4">Bancroft (1944)</ref> was probably the first to show how this can bias a model-based method after model checking. <ref type="bibr" target="#b13">Chatfield (1995)</ref> gave a more comprehensive discussion of the issue. <ref type="bibr" target="#b47">Hennig (2007)</ref> coined the term "goodness-of-fit paradox" (from now on called "misspecification paradox" here) to emphasise that in case model assumptions hold, checking them in fact actively invalidates them. Assume that the original distribution of the data fulfills a certain model assumption. Given a probability α &gt; 0 that the MS test rejects the model assumption if it holds, the conditional probability for rejection under passing the MS test is obviously 0 &lt; α, and therefore the conditional distribution must be different from the one originally assumed. It is this conditional distribution that eventually feeds the model-based method that a user wants to apply.</p><p>How big a problem is the misspecification paradox, and more generally the fact that MS tests cannot technically ensure the validity of the model assumptions? Some authors (e.g., <ref type="bibr" target="#b96">Shuster (2005)</ref>  indeed "pose very different questions to the data"), differences between the conditional and the unconditional behaviour of the MC test should be small. This can be investigated individually for every combination of MS test and main test, and there is no guarantee that the result will always be that the difference is negligible, but in many cases this will be the case.</p><p>This alone does not imply that MS testing is beneficial, though. Also the case of violated model assumptions needs to be studied. In this case, the conditional distribution of the AU test given that the MS test rejects the model assumption, and of the MC test given that the MS test does not reject, do matter.</p><p>Some kinds of visual informal model checking can be thought of as useful in a relatively safe manner if they lead to model rejections only in case of strikingly obvious assumption violations that are known to have an impact (which can be more precisely assessed looking at the data in a more holistic manner than a formal test can). In this case, the probability to reject a true model can be suspected to be very close to zero, in turn not incurring much "pretest bias". But this relies on the individual researcher and their ability to recognise a violation of the model assumptions that matters. On the other hand, starting from around 1980 there were attempts to automatise data analysis, including deciding about model assumptions, in order to allow for the absence of expert statisticians, but also for improving reproducibility <ref type="bibr" target="#b43">(Hand (1984)</ref>; <ref type="bibr" target="#b97">Shyr and Spisic (2014)</ref>).</p><p>A view opposite to Spanos's one, namely that model checking and inference given a parametric model should not be separated, but rather that the problems of finding an appropriate distributional "shape" and parameter values compatible with the data should be treated in a fully integrated fashion, can also be found in the literature <ref type="bibr" target="#b21">(Easterling (1976)</ref>; <ref type="bibr" target="#b20">Draper (1995)</ref>; <ref type="bibr" target="#b16">Davies (2014)</ref>). <ref type="bibr" target="#b16">Davies (2014)</ref> argued that there is no essential difference between fitting a distributional shape, an (in)dependence structure, and estimating a location (which is usually formalised as parameter of a parametric model, but could as well be defined as a nonparametric functional).</p><p>Bayesian statistics allows for an integrated treatment by putting prior probabilities on different candidate models, and averaging their contributions. Robust and nonparametric procedures may be seen as alternatives not only in case model assumptions of model-based procedures are violated; they have also been recommended for uncon-ditional use <ref type="bibr" target="#b42">(Hampel et al. (1986)</ref>; <ref type="bibr" target="#b51">Hollander and Sethuraman (2001)</ref>), making prior model checking supposedly superfluous. Example 1 however shows that "model-free" procedures without MS testing will not always perform very well. All these approaches still make assumptions; the Bayesian approach assumes that prior distribution and likelihood are correctly specified, robust and nonparametric methods still assume data to be i.i.d., or make other structural assumptions violation of which may mislead the inference (see <ref type="bibr" target="#b110">Watson and Holmes (2016)</ref> for a Bayesian view of model misspecification and robustness). So, the checking of assumptions issue does not easily go away, unless it is claimed (as some subjectivist Bayesians do) that such assumptions are subjective assessments and cannot be checked against data; for a contrary point of view see <ref type="bibr" target="#b34">Gelman and Shalizi (2013)</ref>. To our knowledge, however, there is hardly any literature assessing the performance of model checking combined in which the "MC role" is taken by robust, nonparametric or Bayesian inference, but see <ref type="bibr" target="#b9">Bickel (2015)</ref> for a combined procedure that involves model checking and robust Bayesian inference.</p><p>Some authors in the econometric literature <ref type="bibr" target="#b46">(Hendry and Doornik (2014)</ref>; Spanos (2018)) prefer "respecification" of parametric models, i.e., setting up a new parametric model accounting for the detected violation of the model assumptions, to robust or nonparametric approaches in the case that model assumptions are rejected. In some situations, the advantage of respecification is obvious, particularly where a specific parametric form of a model is required, for example, for prediction and simulation. More generally, <ref type="bibr" target="#b100">Spanos (2018)</ref> argued that the less restrictive assumptions of nonparametric or robust approaches such as moment conditions or smooth densities are often untestable, as opposed to the more specific assumptions of parametric models. But this seems unfair, because to the extent that violations from such assumptions cannot be detected for more general models, it cannot be detected that any parametric model holds either. Impossibility results such as in <ref type="bibr" target="#b3">Bahadur and Savage (1956)</ref> or <ref type="bibr" target="#b18">Donoho (1988)</ref> imply that distributions violating conditions such as bounded means, higher order moments, or existing densities are indistinguishably close to any parametric distribution. Spanos was right that nonparametric and robust methods are not 100% safe either, but they will often work under a wider range of distributions than a parametric model. For example, classical robust estimation does safeguard against mixture distributions of the type (1 -ϵ)N + ϵQ, where N refers to a normal distribution, Q to any distribution, 0 &lt; ϵ small enough, which can have arbitrary or non-existing means and cannot be distinguished from a normal distribution with large probability for a given fixed sample size and ϵ small enough. Ultimately parametric respecification can be useful and can be successful in some cases such as sufficiently regular violations of independence where robust and nonparametric tools are lacking. Regarding the setup of interest here, the AU test can legitimately be derived from a parametric respecification of the model. But in many situations it will be hard to find a respecified model that can be confirmed by MS testing of all assumptions (as required by Spanos). Cited results in Section 5 suggest in particular that situations in which a violated model assumption is not detected by the MS test for testing that very assumption can harm the performance of the MC test in a combined procedure. Furthermore, a respecification procedure as implied by Spanos including testing all relevant assumptions is to our knowledge not yet fully formalised and will be hard to formalise given the complexity of the problem, so that currently its performance characteristics in various possible situations cannot be investigated systematically. However, Spanos makes a valid point regarding the dangers of testing certain model assumptions in isolation, as MS as well as AU tests come with their own assumptions that may themselves be violated.</p><p>Another potential objection to model assumption checking is that, in the famous words of George Box, "all models are wrong but some are useful". It may be argued that model assumption checking is pointless, because we know anyway that model assumptions will be violated in reality in one way or another (e.g., it makes some sense to hold that in the real world no two events can ever be truly independent, and continuous distributions are obviously not "true" as models for data that are discrete because of the limited precision of all human measurement). This has been used as argument against any form of model-based frequentist inference, particularly by subjectivist Bayesians (e.g., de Finetti (1974)'s famous "probability does not exist"). <ref type="bibr" target="#b70">Mayo (2018)</ref> however argued that "all models are wrong" on its own is a triviality that does not preclude a successful use of models, and that it is still important and meaningful to test whether models are adequately capturing the aspect of reality of interest in the inquiry. According to Section 2, it is at least worthwhile to check whether the data are incompatible with the model in ways that will mislead the desired model-based inference, which can happen in a Bayesian setting just as well. This does not require models to be "true".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results for Some Specific Test Problems</head><p>In this Section we will review and bring together results from the literature investigating the performance characteristics of combined procedures. Our focus is not on the detailed recommendations, but on general conditions under which combined procedures have been compared to unconditional use of MC or AU test, and have been found superior or inferior. Published results almost exclusively concern simple standard problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The Problem of Whether to Pool Variances</head><p>Historically, the first problem for which preliminary MS testing and combined procedures were investigated was whether to test the equal variances assumption for comparing the means of two samples. Until now this is the problem for which most work investigating combined procedures exists. Let X 1 , X 2 , ..., X n be distributed i.i.d. according to P µ 1 ,σ 2 1 and Y 1 , Y 2 , ..., Y n be distributed i.i.d. according to P µ 2 ,σ 2 2 , where P µ,σ 2 denotes a distribution with mean µ and variance σ 2 . Most but not all literature consider P µ,σ 2 = N (µ, σ 2 ), the normal distribution. If σ 2 1 = σ 2 2 , the standard two-sample t-test using a pooled variance estimator from both samples (MC test) is optimal. For σ 2 1 ̸ = σ 2 2</p><p>Welch's approximate t-test with adjusted degrees of freedom depending on the two individual variances (AU test) is often recommended, see <ref type="bibr" target="#b111">Welch (1938)</ref>; <ref type="bibr" target="#b91">Satterthwaite (1946)</ref>; <ref type="bibr" target="#b112">Welch (1947)</ref>.</p><p>The equal variances assumption is the historical starting point for investigations of the impact of MS testing. Early authors beginning from <ref type="bibr" target="#b4">Bancroft (1944)</ref> did not frame the problem in terms of "making sure that model assumptions are fulfilled", but rather asked, in a pragmatic manner, under what circumstances pooling variances is advantageous. If the two variances are in fact equal or very similar, it is better to use all observations for estimating a single variance hopefully precisely, whereas if the two variances are very different, the use of a pooled variance will give a biased assessment of the variation of the means and their difference.</p><p>It has been demonstrated that the two sample t-test is very robust against violations of equality of variances when sample sizes are equal as shown by <ref type="bibr" target="#b53">Hsu (1938)</ref>; <ref type="bibr" target="#b92">Scheffé (1970)</ref>; <ref type="bibr" target="#b82">Posten et al. (1982)</ref>; <ref type="bibr" target="#b119">Zimmerman (2006)</ref>. When both variances and sample sizes are unequal, the probability of the Type-I error exceeds the nominal significance level if the larger variance is associated with the smaller sample size and vice versa <ref type="bibr" target="#b119">(Zimmerman (2006)</ref>; <ref type="bibr" target="#b114">Wiedermann and Alexandrowicz (2007)</ref>; Moder (2010)), which is amended by Welch's t-test. <ref type="bibr" target="#b6">Bancroft and Han (1977)</ref> published a bibliography of the considerable amount of literature on that problem available already at that time. One reason for the popularity of the variance pooling problem in early work is that, as long as normality is assumed, only the ratio of the variances needs to be varied to cover the case of violated model assumptions, which makes it easier to achieve theoretical results without computer-intensive simulations.</p><p>Work that investigated sizes and/or power of combined procedures involving an MS test for variance equality for a main test of the equality of means, theoretically or by simulation, comprises <ref type="bibr" target="#b41">Gurland and McCullough (1962)</ref>; <ref type="bibr" target="#b5">Bancroft (1964)</ref>; <ref type="bibr" target="#b31">Gans (1981)</ref>; <ref type="bibr" target="#b75">Moser et al. (1989)</ref>; <ref type="bibr" target="#b40">Gupta and Srivastava (1993)</ref>; <ref type="bibr" target="#b74">Moser and Stevens (1992)</ref>; <ref type="bibr">Albers et al. (2000a)</ref>; <ref type="bibr" target="#b121">Zimmerman (2014)</ref>. General findings are that the combined procedure can achieve a competitive performance regarding power and size beating Welch's t-test only in small subspaces of the parameter space with specific sample sizes. None of these authors recommends it for default use; <ref type="bibr" target="#b74">Moser and Stevens (1992)</ref> recommended to never test the equal variances assumption. Often the unconditional Welch's t-test is recommended, which is only ever beaten by a very small margin by the MC test or the combined procedure in specific situations. Occasionally the MC test is recommended conditionally on sample sizes being very similar.</p><p>Markowski and <ref type="bibr" target="#b68">Markowski (1990)</ref> hinted at what the problem with the combined procedure is. They evaluated the F -test as MS test of homogeneity of variances for detecting deviations from variance equality that are known to matter for the standard t-test by simulations, and showed that the F -test is ineffective at finding these. Like <ref type="bibr" target="#b31">Gans (1981)</ref>, they also involved non-normal distributions in their comparisons. This did not lead to substantially different recommendations. <ref type="bibr">Albers et al. (2000a)</ref> presented a second order asymptotic analysis of the combined procedure for pooling variances with the F -test as MS test. They argue that this procedure can only achieve a better power than the MC test if the combined procedure also has a larger type 1 error probability. This means that there are only two possibilities for the combined procedure to improve upon the MC test. Either the combined procedure is anti-conservative, i.e., violates the desired test level, which would be deemed unacceptable in many applications, or the size of the MC test is smaller than the nominal level, which if its assumptions are not fulfilled is sometimes the case. <ref type="bibr">Albers et al. (2000b)</ref> extend these results to the analysis of a more general problem for distributions P θ,τ from a parametric family with two parameters θ and τ , where θ = 0 is the main null hypothesis of interest, and the decision between an MC test assuming τ = 0 and an AU test without that assumption is made based on an MS test testing τ = 0. In the two-sample variance pooling problem, τ could be the logarithm of the ratio between the variances; a simpler example would be the choice between Gauss-and t-test in the one-sample problem, where the MS test tests whether the variance is equal to a given fixed value. Once more, the combined procedure can only achieve better power at the price of a larger size, potentially being anti-conservative. Another key aspect is that the authors introduced a correlation parameter ρ formalising the dependence between the MS-test and the main tests. In line with the discussion in Section 4, they state that for strong dependence preliminary testing is not sensible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Tests of Normality in the One-sample Problem</head><p>The simplest problem in which preliminary misspecification testing has been investigated is the problem of testing a hypothesis about the location of a sample. The standard model-based procedure for this is the one-sample Student's t-test. It assumes the observations X 1 , X 2 , ..., X n to be i.i.d. normal. For non-normal distributions with existing variance the t-test is asymptotically equivalent to the Gauss-test, which is asymptotically correct due to the CLT. The t-test is therefore often branded robust against non-normality if the sample is not too small, see, e.g., <ref type="bibr" target="#b7">Bartlett (1935)</ref>; <ref type="bibr" target="#b66">Lehmann and Romano (2005)</ref>. An issue is that the quality of the asymptotic approximation does not only depend on n, but also on the underlying distributional shape, as the speed of improvement of the normal approximation is not uniform. Very skew distributions or extreme outliers can affect the power of the t-test for large n, see <ref type="bibr" target="#b15">Cressie (1980)</ref>.</p><p>Another problem with the application of the CLT is the non-robustness of the mean as functional in the space of distributions <ref type="bibr" target="#b42">(Hampel et al. (1986)</ref>). Consider a situation in which the interest is in inference about µ assuming the underlying distribution as N (µ, σ 2 ). If in fact the underlying distribution is Q µ.σ 2 ,ϵ,x = (1 -ϵ)N (µ, σ 2 ) + ϵδ x with small ϵ and x far away from µ, δ x being the Dirac measure in x, EQ µ.σ 2 ,ϵ,x may be arbitrarily far away from µ despite d(N (µ, σ 2 ), Q µ.σ 2 ,ϵ,x ) small for most sensible distance measures d between distributions. If observations x are interpreted as outliers, the parameter of scientific interest may still be µ rather than EQ µ.σ 2 ,ϵ,x , but the CLT will grant consistency of the sample mean for the latter, not the former.</p><p>Cressie mentions that the biggest problems for the t-test occur for violations of independence, however we are not aware of any literature examining of independence testing combined with the t-test.</p><p>Some work focuses just on the quality of the MS tests without specific reference to its effect on subsequent inference and combined procedures, see <ref type="bibr" target="#b86">Razali and Wah (2011)</ref>; <ref type="bibr" target="#b72">Mendes and Pala (2003)</ref>; <ref type="bibr" target="#b24">Farrell and Rogers-Stewart (2006)</ref>; <ref type="bibr" target="#b60">Keskin (2006)</ref>. This is of limited use, as it does not address which alternatives to normality are particularly problematic and for which a subsequent t-test can still do well. <ref type="bibr" target="#b94">Schoder et al. (2006)</ref> and <ref type="bibr" target="#b58">Keselman et al. (2013)</ref> investigated normality tests regarding its use for subsequent inference without explicitly involving the later main test. Both advised against the Kolmogorov-Smirnov test. <ref type="bibr" target="#b58">Keselman et al. (2013)</ref> concluded that the Anderson-Darling test is the most effective one at detecting non-normality relevant to subsequent t-testing, and they suggested that for deciding whether the MC test should be used, the MS test be carried out at a significance level larger than 0.05, for example, 0.15 or 0.20, in order to increase the power, as all these tests may have difficulties to detect deviations that are problematic for the t-test.</p><p>Another group of work examines running a t-test conditionally on passing normality by a preliminary normality test. Most of these do not consider what happens if normality is rejected. <ref type="bibr" target="#b22">Easterling and Anderson (1978)</ref> considered various distributions such as normal, uniform, exponential, two central and two non-central t-distributions. They used both the Anderson-Darling and the Shapiro-Wilk normality tests. In the case that normality was passed, they compared the empirical distribution of the resulting t-values to Student's t-distribution. This worked well when the samples were drawn from the normal distribution (in which case the standardised residuals, on which normality tests can be run, are ancillary statistics independent of the estimated mean and variance).</p><p>For symmetric non-normal distributions, the results were mixed, and for situations where the distributions were asymmetric, the distribution of the t-values conditionally on not rejecting the normal assumption did not resemble a Student's t-distribution, which they took as an argument against the practice of preliminary normality testing. As a result they favoured a nonparametric approach. <ref type="bibr" target="#b95">Schucany and Ng (2006)</ref> investigated the conditional type 1 error rate of the one sample t-test given that the sample has passed a test for normality for data from normal, uniform, exponential, and Cauchy populations. They conclude that the MS test makes matters worse in the sense that the Type I error rate is further away from the nominal 5% (lower for the uniform and Cauchy, higher for the exponential) for data that pass the normality test than when the t-test is used unconditionally, and this becomes worse for larger sample sizes. For the Cauchy distribution they also investigated running a Wilcoxon signed rank test as AU test conditionally on rejecting normality, which works worse than using the AU test unconditionally. <ref type="bibr" target="#b88">Rochon and Kieser (2011)</ref> came to similar conclusions using a somewhat different collection of MS tests and underlying distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Tests of Normality in the Two-sample Problem and Oneway ANOVA</head><p>For the two-sample problem, the Wilcoxon-Mann-Whitney (WMW) rank test is a popular alternative to the two-sample t-test with (in the context of preliminary normality testing) mostly assumed equal variances. In principle, most arguments and results from the one-sample problem apply here as well, with the additional complication that normality is assumed for both samples, and can be tested either by testing both samples separately, or by pooling residuals from the mean. As for the one-sample problem, there are also claims and results that the two-sample t-test is rather robust to violations of the normality assumption <ref type="bibr" target="#b54">(Hsu and Feldt (1969)</ref>; <ref type="bibr" target="#b83">Rasch and Guiard (2004)</ref>), but also some evidence that this is sometimes not the case (see Example 1), and that the WMW rank test can be superior and does not lose much power even if normality is fulfilled <ref type="bibr" target="#b76">(Neave and Granger (1968)</ref>). <ref type="bibr" target="#b25">Fay and Proschan (2010)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Linear Regression</head><p>In standard linear regression, </p><formula xml:id="formula_4">y i = β 0 + β 1 x 1i + . . . + β p x pi + e i , i = 1, . . . ,</formula><formula xml:id="formula_5">β k = 0</formula><p>by what is interpreted as MS test, the conditionally estimated β k will be systematically too large in absolute value, and can through dependence on the estimated β j also be strongly dependent on the MC test.</p><p>Traditional model selection approaches such as forward selection and backward elimination are often based on such tests and have been analysed (and criticised) a lot in the literature. We will not review this literature here. There is sophisticated and innovative literature on post-selection inference in this problem. <ref type="bibr" target="#b8">Berk et al. (2013)</ref> propose a procedure in which the main inference is adjusted for simultaneous testing taking into account all possible sub-models that could have been selected. <ref type="bibr" target="#b23">Efron (2014)</ref> uses bootstrap methods to do inference that takes the model selection process into account. Both approaches also involve other MS testing such as for normality, homoscedasticity, or linearity assumptions, as long as combined procedures are fully specified. <ref type="bibr" target="#b118">Zhang et al. (2022)</ref> provide a recent survey of methods of this kind. For a critical perspective see <ref type="bibr" target="#b64">Leeb and Pötscher (2005)</ref>; <ref type="bibr" target="#b65">Leeb et al. (2015)</ref>, noting particularly that asymptotic results regarding the distribution of post-selection statistics (i.e., results of combined procedures) will not be uniformly valid for finite samples. In econometrics, David Hendry and co-workers developed an automatic modeling system that involves MS testing and conditional subsequent testing with adjustments for decisions in the modeling process, see, e.g., <ref type="bibr" target="#b46">Hendry and Doornik (2014)</ref>. They mentioned that their experience from experiments is that involving MS tests does not affect the final results much when the model assumptions for the final procedure are fulfilled. However, to our knowledge these experiments are not published anywhere. Earlier, some authors such as <ref type="bibr" target="#b90">Saleh and Sen (1983)</ref> analysed the effect of preliminary variable selection testing on later conditional main testing. <ref type="bibr" target="#b36">Godfrey (1988)</ref> listed a plethora of MS tests to test the various assumptions of linear regression. However, no systematic way to apply these tests was discussed. In fact, Godfrey noted that the literature left more questions open rather than answered. Some of these questions are: (i) the choice among different MS tests, (ii) whether to use nonparametric or parametric tests, (iii) what to do when any of the model assumptions are invalid, (iv) some potential problems with MS testing such as repeated use of data, multiple testing and pre-test bias. <ref type="bibr" target="#b37">Godfrey (1996)</ref> concluded that efforts should be made to develop "attractive", useful and simple combined procedures as these were lacking at the time; to a large extent this still is the case. One suggestion was to use the Bonferroni correction for each test as "the asymptotic dependence of test statistics is likely to be the rule, rather than the exception, and this will reduce the constructive value of individual checks for misspecification". <ref type="bibr" target="#b35">Giles and Giles (1993)</ref> reviewed the substantial amount of work done in econometrics regarding preliminary testing in regression up to that time, a limited amount of which is about MC and/or AU tests conditionally on MS tests. This involves pre-testing of a supposedly known fixed variance value, homoscedasticity, and independence against auto-correlation alternatives. The cited results are mixed. <ref type="bibr" target="#b61">King and Giles (1984)</ref> comment positively on a combined procedure in which absence of auto-correlation is tested first by a Durbin-Watson or t-test. Conditionally on the result of that MS test, either a standard t-test of a regression parameter was run (MC test), or a test based on an empirically generalised least squares estimator taking auto-correlation into account (AU test). In simulations, the combined procedure performs similarly to the MC test and better than the AU test in absence of auto-correlation, and similarly to the AU test and better than the MC test in the presence of auto-correlation. Also here it is recommended to run the MS test at a level higher than the usual 5%. Most related post-1993 work in econometrics seems to be on estimation after pre-testing, and regression model selection. <ref type="bibr" target="#b79">Ohtani and Toyoda (1985)</ref> proposed a combined procedure for testing linear hypotheses in regression conditionally on testing for known variance. <ref type="bibr" target="#b105">Toyoda and Ohtani (1986)</ref> tested the equality of different regressions conditionally on testing for equal variances. In both papers, power gains for the combined procedure are reported, which are sometimes but not always accompanied by an increased type 1 error probability.</p><p>While not defining a combined procedure or investigating specific MS tests, <ref type="bibr" target="#b93">Schmidt and Finan (2018)</ref> highlight biases resulting from applying transformations to the response variables in order to achieve better normality of residuals. They argue that inference from normality is often valid with large sample sizes even with non-normal residuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Other Problems</head><p>Some specific problem-adapted combined procedures have been discussed in the literature.</p><p>In a two-treatment, two-period cross-over trial, patients are randomly allocated either to one group that receives treatment A followed by treatment B, or to another group that receives the treatments in the reverse order. The straightforward analysis of such data could analyse within-patients differences between the effects of the two treatments by a paired test (MC test). This requires the assumption that there is no "carry-over", i.e., no influence of the earlier treatment on the effect of the later treatment. In case there is carry-over, the somewhat wasteful analysis of the effect of the first treatment only for each patient is safer (AU test). <ref type="bibr" target="#b39">Grizzle (1967)</ref> proposed a combined procedure that became well established for some time. It consists of computing a score for each patient that contrasts the two treatment effects with the baseline values, and tests, e.g., using a two-sample t-test, whether this is the same on average in both groups, corresponding to the absence of carry-over on average (MS test). <ref type="bibr" target="#b28">Freeman (1989)</ref> analysed this combined procedure analytically under a normal assumption and potential existence of carry-over, comparing it to both the MC test and the AU test run unconditionally. He observed that due to strong dependence between the MS test and both the MC-and the AU-test, the combined procedure has more or less strongly inflated type 1 errors whether there is carry-over or not. Its power behaves typically for combined procedures, being better than the AU test but worse than the MC test in absence of carry-over and the other way round in its presence. Overall Freeman advises against the use of this procedure.</p><p>Similarly, <ref type="bibr" target="#b55">Kahan (2013)</ref> advised against a combined procedure involving an MS test for the presence of interactions in a situation in which multiple treatments are assessed in a single trial, in order to decide whether a factorial analysis assuming no interactions should be used (MC test) rather than analysing the data assuming a four-arm trial with interactions (AU test). Often the MS test does not have enough power to detect interactions, but will also bias the analysis due to substantial dependence with the main tests. MC test and AU test on their own performed unsatisfactorily as well. <ref type="bibr" target="#b55">Kahan (2013)</ref> ultimately recommended to run both MC and AU test and to only take results as meaningful in case the two tests coincide.</p><p>Campbell and Dean (2014) analysed combined procedures for the Cox proportional hazard model with covariates, in which the assumption of a constant hazard rate over time is tested by a Grambsch and Therneau test (MS test). They considered a number of different approaches for the AU tests. Dependence between the MS test and the main tests produced inflated type 1 error probabilities with some approaches strongly and some mildly affected. The authors then applied a permutation adjustment to the combined procedure in case the covariate of interest is a treatment indicator. The distribution of the p-value of the combined procedure under the H 0 of no treatment effect can then be investigated permuting the treatment labels. This achieved unbiased type 1 error probabilities, with the power depending on the situation considered. This idea could also be applied in other situations where the null hypothesis is that a certain covariate, potentially a group indicator, has no effect. <ref type="bibr" target="#b84">Rasch et al. (2011)</ref> assessed the statistical properties of a three-stage procedure including testing for normality and for homogeneity of the variances taking into account a number of different distributions, and ratios of the standard deviation. They considered three main statistical tests, the Student's t-test, the Welch's t-test and the WMW test. For the MS testing, they used the Kolmogorov-Smirnov test for testing normality and Levene's test for testing the homogeneity of the variances of the two generated samples <ref type="bibr" target="#b67">(Levene (1960)</ref>). If normality was rejected by the Kolmogorov-Smirnov test, the WMW test was used. If normality was not rejected, the Levene's test was run and if homogeneity was rejected, the Welch's t-test was used and if homogeneity was not rejected, the standard t-test was used. Welch's t-test performed so well overall that the authors recommended its unconditional use, which is in line with recommendations by <ref type="bibr" target="#b83">Rasch and Guiard (2004)</ref> from investigations of the robustness of various tests against non-normality. All of the investigated distributions had finite kurtosis, meaning that the tails were not really heavy. <ref type="bibr" target="#b71">McGuirk et al. (1993)</ref> proposed a comprehensive strategy for linear regression involving a number of misspecification tests. They investigated its power against various types of misspecified models and recommended alternative models in case of misspecification, but did not investigate the performance of the resulting combined procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">More Than One Misspecification Test</head><p>Campbell (2021) investigated a combined procedure in which MS tests test for zero inflation and overdispersion in a Poisson regression model, with AU tests based on negative binomial, zero-inflated Poisson, and zero-inflated negative binomial models depending on the outcomes of two MS tests. Results turn out to be problematic at least in some situations for unconditional use of the MC or AU tests, but also for the combined procedures (model selection by Akaike's Information Criterion and the Bayesian Information Criterion was also involved as an alternative to using MS tests). The combined procedure using MS tests was recommended for large sample sizes but may result in considerably inflated type 1 error probabilities for small samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.">Discussion</head><p>Although many authors have, in one way or another, investigated the effects of preliminary MS testing or later application of model-based procedures, there are severe limitations in the existing literature. Only a few papers have compared the performance of a fully specified combined procedure with unconditional uses of both the MC and the AU tests. Some of these have only looked at type 1 error probabilities but not power (in many situations the behaviour of power is connected to the type 1 error, and improved power comes at the price of an increased type 1 error), and some have only looked at the situation in which the model assumption is in fact fulfilled. Some have studied setups in which either the unconditional MC or the AU test works well across the board, making a combined procedure superfluous, although it is widely acknowledged that situations in which either unconditional test can perform badly depending on the unknown data generating process, do exist. In some other situations not only the combined procedure but also MC and AU tests on their own perform unsatisfactorily.</p><p>Reasons why authors advised against model checking in specific situations were:</p><p>(a) The MC test was better or at least not clearly worse than the AU test for all considered distributions in which the model assumptions of the MC test were not fulfilled (in which case the MC test can be used unconditionally). In some cases this has happened because authors did not include existing distributions in their simulations with which the MC test would have had bigger problems, e. g., severely heavy tailed distributions are missing from <ref type="bibr" target="#b88">Rochon and Kieser (2011)</ref>.</p><p>(b) The AU test was not clearly worse than the MC test where model assumptions of the MC test were fulfilled (in which case the AU test can be used unconditionally). For example, the Welch and Sattertwaite tests work very well for equal variances in Section 5.1.</p><p>(c) The MS test did not work well distinguishing situations in which the MC test was better from situations in which the AU test was better, possibly despite being good at testing just the formal model assumption.</p><p>(d) Due to dependence, the application of the MS test distorted the performance of the conditionally performed tests (often to the effect that the combined procedure was anticonservative).</p><p>(e) The combined procedure was branded theoretically invalid, occasionally even when performing well in simulations, <ref type="bibr" target="#b87">Rochon et al. (2012)</ref>.</p><p>(f) In some work shortcomings of model checking before running the MC test were highlighted, but running the MC test without checking did not look overall convincing either, and both were not compared with a full combined procedure or a specific AU test, e.g., <ref type="bibr" target="#b22">Easterling and Anderson (1978)</ref>; <ref type="bibr" target="#b95">Schucany and Ng (2006)</ref>. <ref type="bibr" target="#b87">Rochon et al. (2012)</ref> explicitly stated that the full combined procedure performs better in their simulations than what could be expected from looking in an isolated manner at the effect of MS testing on each single one of the main tests.</p><p>For model checking to be worthwhile, points (a)-(d) need to be avoided. Point (e) arguably is only an issue to the extent that the actual performance of the combined procedure is in fact bad, which seems to be covered by points (a)-(d) already. Regarding point (f), it is clear that general issues with MS testing exist, but this does not necessarily mean that there is a better alternative.</p><p>A further recurring theme in the work investigating combined procedures is a recommendation to use a higher level for the MS test than the conventional 5%, due to the difficulty of the involved MS tests to find certain violations of the model assumptions that are critical for the later MC test.</p><p>Comparing a full combined procedure with unconditional use of the MC test or the AU test, a typical pattern is that under the model assumption for the MC test, the MC test is best regarding power, and the combined procedure performs between the unconditional MC test and AU test, and if that model assumption is violated, the AU test is best, and the combined procedure is once more between the MC test and the AU test, see Example 1. Such results can be interpreted charitably for the combined procedure, protecting against the worst performances achieved by any of the main tests on their own. It seems to us that part of the criticism of the combined procedure is motivated by the fact that it does not do what some seem to expect or hope it to do, namely, to help making sure that model assumptions are fulfilled, and to otherwise leave performance characteristics untouched.</p><p>A detailed look at the results reveals that the combined procedures are almost always competitive with at least one of the unconditional tests, and often with them both (e.g., in <ref type="bibr" target="#b63">Lantz et al. (2016)</ref>). It is clear, though, that recommendations need to depend on the specific problem and the specific tests involved. Results often also depend on in what way exactly model assumptions of the MC test are violated, which is hard to know without some kind of data dependent reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">A Positive Result for Combined Procedures</head><p>The overall message from the literature does not seem very satisfactory. On the one hand, model assumptions are important and their violation can severely damage results. On the other hand, investigating the performance of combined procedures reveals severe limitations.</p><p>In this section, we present a setup and a result that makes us assess the impact of preliminary model testing somewhat more positively. A characteristic of the literature analysing combined procedures is that they compare the combined procedure with unconditional MC or AU tests both in situations where the model assumption of the MC test is fulfilled, or not fulfilled. However, they do not investigate a situation in which the MS test can do what it is supposed to do, namely to distinguish between these situations.</p><p>We here model an idealised setup in which researchers in a certain field, say, analyse many data sets using the same tests based on certain model assumptions, and come across a certain percentage 0 ≤ λ ≤ 1 of situations in which the model assumptions are fulfilled, and a percentage of 1 -λ situations in which the model assumptions are violated in a certain way.</p><p>Is such a setup relevant? Obviously it is not realistic that there are only two distributions possible, one of which fulfills the model assumptions of the MC test. We wanted to keep the setup simple, but of course one could look at mixtures of a wider range of distributions, even a continuous range (for example, for ratios between group-wise variances). In any case, the setup is more flexible and one might say realistic than looking at λ = 0 and λ = 1 only, which is what has been done in the literature up to now. The aim here is to show in what sense the combined procedure can be better than both MC and AU tests applied unconditionally, and similar effects will likely be obtained in more complex setups. Also, model assumptions will of course never hold precisely, but having a certain probability that the model is wrong in a really problematic way, whereas otherwise the nominal performance of the MC test is a good approximation, does not seem unrealistic. The setup has a certain Bayesian flavor, but a researcher may want to use λ as a simple device for decision support rather than being required to set up priors for λ along with all other model parameters.</p><p>Using the notation from Section 3, let P θ be a distribution that fulfills the model assumptions of the MC test, and Q ∈ M \ M Θ a distribution that violates these assumptions. For considerations of power, let the null hypothesis of the main test be violated, i.e., θ ̸ ∈ Θ 0 and Q ̸ ∈ M * (an analogous setup is possible for considerations of size). We may observe data from P θ or from Q. Assume that a data set is with probability λ ∈ [0, 1] generated from P θ and with probability 1 -λ from Q (we stress that as opposed to standard mixture models, λ governs the distribution of the whole data set, not every single observation independently). The cases λ = 0 and λ = 1 are those that have been treated in the literature, but only if λ ∈ (0, 1) the ability of the MS test to inform the researcher whether the data are more likely from P θ or from Q is actually required.</p><p>Figure <ref type="figure">6</ref> is based on Example 1 with P θ being the normal and Q the t 3 -distribution. In this situation, for λ = 0 (t 3 ; model assumption violated), the AU test (WMW) is best and the MC test (t test) is worst. For λ = 1, both MC test and combined procedure reach about the same power, and the AU test is worst. The powers of all three tests are linear functions of λ, and the consequence is that the combined procedure performs better than both unconditional tests over the best part of the range of λ, and never much worse than the best. The latter can be seen in many setups of this kind. This good result is somewhat contrasted by a slightly inflated type 1 error probability of the combined procedure though, see Example 1.</p><p>On top of the notation from Section 3, P λ stands for distribution of the overall two step experiment, i.e., first selecting either P = P θ or P = Q with probabilities λ, 1 -λ respectively, and then generating a data set z from P . The events of rejection of the respective</p><formula xml:id="formula_6">H 0 are denoted R M S = {Φ M S (z) = 1}, R M C = {Φ M C (z) = 1}, R AU = {Φ AU (z) = 1}, R C = {Φ C (z) = 1}</formula><p>, where C refers to the combined procedure. Here are some assumptions: The following Lemma states that the combined procedure has better power than both the MC test and the AU test for at least some λ. Although this in itself is not a particularly strong result, in many situations, according to our experience, the range of λ for which this holds is quite large. Furthermore the result concerns general models and choices of tests, whereas to our knowledge everything that already exists in the literature is for specific choices. Despite the somewhat restrictive set of assumptions, none of the involved tests and distributions is actually specified, so that the Lemma (at least with a relaxed version of (IV)) applies to a very wide range of problems.</p><formula xml:id="formula_7">(I) ∆ θ = P θ (R M C ) -P θ (R AU ) &gt; 0, (II) ∆ Q = Q(R AU ) -Q(R M C ) &gt; 0, (III) α * M S = Q(R M S ) &gt; α M S = P θ (R M S ),<label>(</label></formula><p>Lemma 1. Assuming (I)-(IV), ∃λ ∈ (0, 1) such that both P λ (R C ) &gt; P λ (R M C ) and P λ (R C ) &gt; P λ (R AU ).</p><p>Proof. Obviously,</p><formula xml:id="formula_8">P λ (R M C ) = λP θ (R M C ) + (1 -λ)Q(R M C ), P λ (R AU ) = λP θ (R AU ) + (1 -λ)Q(R AU ).</formula><p>By (I), for λ = 1 : P λ (R M C ) &gt; P λ (R AU ) and, by (II), for λ = 0 : P λ (R AU ) &gt; P λ (R M C ).</p><p>As P λ (R M C ) and P λ (R AU ) are linear functions of λ, there must be λ * ∈ (0, 1) so that</p><formula xml:id="formula_9">P λ * (R AU ) = P λ * (R M C ). Obtain P λ * (R M C ) = P λ * (R AU ) ⇔ λ * P θ (R M C ) + (1 -λ * )Q(R M C ) = λ * P θ (R AU ) + (1 -λ * )Q(R AU ) ⇔ λ * (∆ θ + ∆ Q ) = ∆ Q ⇔ λ * = ∆ Q ∆ θ + ∆ Q .</formula><p>This yields, by help of (IV),</p><formula xml:id="formula_10">P λ * (R C ) = λ * P θ (R C ) + (1 -λ * )Q(R C ) = λ * [α M S P θ (R AU |R M S ) + (1 -α M S )P θ (R M C |R c M S )] + (1 -λ * ) [α * M S Q(R AU |R M S ) + (1 -α * M S )Q(R M C |R c M S )] = λ * [α M S P θ (R AU ) + (1 -α M S )P θ (R M C )] + (1 -λ * ) [α * M S Q(R AU ) + (1 -α * M S )Q(R M C )] = ∆ Q ∆ θ + ∆ Q [-α M S ∆ θ -α * M S ∆ Q ] + α * M S ∆ Q + P λ * (R M C ) = ∆ Q -α M S ∆ θ -α * M S ∆ Q + α * M S ∆ θ + α * M S ∆ Q ∆ θ + ∆ Q + P λ * (R M C ) = ∆ θ ∆ Q ∆ θ + ∆ Q [α * M S -α M S ] + P λ * (R M C ) = ∆ θ ∆ Q ∆ θ + ∆ Q [α * M S -α M S ] + P λ * (R AU ). ∆ θ ∆ Q ∆ θ +∆ Q [α * M S -α M S</formula><p>] is larger than zero by (I)-(III), so P λ * (R C ) is larger than both P λ * (R M C ) and P λ * (R AU ). Proof. This follows from the continuity of the sums and products in the proof of Lemma 1.</p><p>Example 2. For given λ, error probabilities of all procedures are just convex combinations of the error probabilities for λ = 0 and λ = 1. In a given situation with sample sizes known in advance, simulations as in Example 1 can be used, together with an assumed value of λ, in order to compare the procedures and to preselect an "optimal" one. This easily extends to more than two possible distributions. Assume in the situation of Example 1 that a researcher commits themselves to expect an approximate normal distribution with probability 1 2 , an approximate t 3 -distribution with probability 1 4 and an approximate skew normal distribution with probability 1 4 (if measurements can take negative values, the exponential does not seem to be a valid option; on the other hand, in situations in which only positive values can be taken, one could simulate, e.g., zero-truncated normal distributions, and even discreteness of data, e.g., knowledge that they all come with at most one digit after the decimal point, can be simulated). Obviously this does not mean that it is required that no other situation can occur, it just examines a "point of orientation", and is surely more informative than a standard consideration of the nominal model assumption only. This yields the type 2 (type 1 in brackets) error probabilities .1641 (.049) for <ref type="bibr">Welch's t-test, 0.1303 (.048)</ref> for <ref type="bibr">WMW, 0.1250 (0.052)</ref> for the combined procedure, and .1619 (0.048) for the permutation test, using the values in Table <ref type="table" target="#tab_3">1</ref>. The combined procedure does best according to power here, and for a good range of choices of "prior probabilities", although anti-conservativity is a concern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Given that statisticians often emphasise that statistical inference relies on model assumptions, and that these need to be checked, the literature investigating this practice is surprisingly critical. In some setups either running a less constrained test or running the model-based test without preliminary testing have been found superior to the combined procedure involving preliminary MS testing. This is in contrast to a fairly general view among statisticians that model assumptions should be checked. The existence of situations in which performance characteristics rely strongly on whether model assumptions are fulfilled or not, has been acknowledged also by authors that were more critical of preliminary testing, and therefore there is certainly a role for model checking. There is however little elaboration of its benefits in the literature. A key contribution of the present work is the investigation of general combined procedures in a setup in which both distributions fulfilling and violating model assumptions can occur. This is more favourable for combined procedures than just looking at either fulfilled or violated model assumptions in isolation. We believe that much of the literature gives a somewhat too pessimistic assessment of combined procedures involving MS testing (some reasons are listed in Section 5.7), and that model checking (and drawing consequences from the result) is more useful than some of the literature suggests. The fact that preliminary assumption checking technically violates the assumptions it is meant to secure, is probably assessed more negatively from the position that models can and should be "true", whereas it may be a rather mild problem if it is acknowledged that model assumptions, while providing ideal and potentially optimal conditions for the application of model-based procedures, are not necessary conditions for their use.</p><p>On the other hand, we believe that model checking is widely misconceived; its role should not be to make sure that the formal assumptions hold (be it approximately), but rather to find the particular violations of model assumptions that are most problematic in terms of level and power. With a better understanding of this point, research can be directed at finding MS tests (or more general decision rules) that fulfill the latter aim better.</p><p>Lemma 1 gives an idea of the required ingredients for successful model checking, i.e., conditions for the combined procedure to be superior to both the MC and the AU test. In order to put this into practice, the researcher should have at least a rough idea about what kinds of deviations from the model assumptions of the MC test may happen, although one may also use "worst cases" (such as distributions with non-existing variances for t-tests) as a starting point. Call {P θ } the family of distributions that fulfill the model assumptions of the MC test, and Q a possible distribution that violates them; one can also involve different options for Q. If available, prior information about in what way model assumptions may be violated should be used, as also emphasised by <ref type="bibr" target="#b104">Tijmstra (2018)</ref> as key ingredient for model checking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a)</head><p>The MC test should be clearly better than the AU test if its model assumptions are fulfilled (otherwise the unconditional AU test can be used without much performance loss).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b)</head><p>The AU test should be clearly better than the MC test for Q (otherwise the unconditional MC test can be used without much performance loss).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(c)</head><p>The MS test should be good at distinguishing {P θ } from Q.</p><p>(d) The MS test Φ M S should be approximately independent of both Φ M C and Φ AU under {P θ } and Q.</p><p>In practice, it is not known what Q will be encountered, but given the unsatisfactory state of the art, developing combined procedures fulfilling (a)-(d) based on realistic choices of Q seems a promising approach to improve matters. Following the literature, in some situations it will be advantageous to run the MS test at a higher level than usual. A reviewer suggested that combined procedures could be generalised by using the result of the MS test to estimate weights for the MC and AU test to combine their results in a continuous manner.</p><p>Considering informal (visual) model checking, issues (a) and (b) are not different from formal combined procedures, although the visual display may help to pick a suitable AU test (be it implicitly by formulating a model that does not require a rejected assumption). An expert data analyst may do better based on suitable plots than existing formal procedures regarding issue (c); many users will probably do worse (see <ref type="bibr" target="#b50">Hoekstra et al. (2012)</ref> for a study investigating misconceptions and lack of knowledge about model checking among empirical researchers). Issue (d) may be plausible if displays are used in which the parameters tested by the MC and AU test such as location or regression parameters do not have a visible impact, such as residual plots, although there is a danger of this being critically violated in case the AU test is chosen based on what is seen in the plots.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Diagram for a combined procedure involving misspecification (MS) testing for deciding which main test is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Corollary 1 .</head><label>1</label><figDesc>Assuming (I)-(III), Lemma 1 still holds if there is a small enough δ &gt; 0 (dependent on the involved probabilities) so that|P θ (R M C |R M S ) -P θ (R M C |R c M S )|, |P θ (R AU |R M S ) -P θ (R AU |R c M S )|, |Q(R M C |R M S ) -Q(R M C |R c M S )|, and |Q(R AU |R M S ) -Q(R AU |R c M S )| are all smaller than δ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head/><label/><figDesc>Users do not normally know before seeing the data, which of these distributions is more relevant in their situation. Therefore surely there is a demand for a test or any formal rule to distinguish between situations in which the WMW test (or any other specific alternative to the t-test) is better, and situations in which the t-test is better, based on the observed data. But this problem is different from distinguishing normal from</figDesc><table/><note><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p>;</p><ref type="bibr" target="#b69">Maydeu-Olivares et al. (2009)</ref></p>;</p><ref type="bibr" target="#b50">Hoekstra et al. (2012)</ref></p>;</p><ref type="bibr" target="#b85">Ravichandran (2012)</ref></p>;</p><ref type="bibr" target="#b0">Abdulhafedh (2017)</ref></p>;</p><ref type="bibr" target="#b117">Wu et al. (2019)</ref></p>;</p><ref type="bibr" target="#b44">Hasler et al. (2020)</ref></p>). Guidelines for statistical analysis plans in clinical trials advise to specify in advance how to test the model assumptions and what to do in case they are rejected</p><ref type="bibr" target="#b30">(Gamble et al. (2017)</ref></p>; van't Veer and Giner-Sorolla (2016) make a similar case for social psychology), whereas</p><ref type="bibr" target="#b115">Williams and Albers (2019)</ref> </p>advise against specifying an algorithmic "decision tree" for model assumption checks when pre-registering studies.</p>Regarding the setup above, different authors arrive at different conclusions. Whereas both</p><ref type="bibr" target="#b87">Rochon et al. (2012)</ref> </p>and</p><ref type="bibr" target="#b25">Fay and Proschan (2010)</ref> </p>advised against normality testing, Fay and Proschan (2010) recommended the WMW test if in doubt, because the t-test can strongly deteriorate in the presence of outliers and heavy tails. On the other hand,</p><ref type="bibr" target="#b87">Rochon et al. (2012)</ref> </p>preferred the t-test, based on simulations on various distributions with light tails. non-normal distributions, as which this is often framed, and which is what a normality test nominally addresses. In fact, the situation is ambiguous, and a combined procedure involving normality testing can well be competitive, see Example 1.</p>Example 1. For illustration consider the simulation of a two-sample situation with i.i.d. data within the two samples i = 1, 2, and sample sizes n 1 = 20, n 2 = 30. We chose</p>Welch's two-sample t-test (Welch (1938)</p>) as MC test, the WMW test as AU test, and the Shapiro-Wilk test (on aggregated residuals from the mean, at level 5% as all involved tests) as MS test for defining a combined procedure. It might be argued that using nonparametric, resampling-based, or robust methods without MS testing could be preferable. Therefore we also included a permutation test of the difference between group means</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc/><table><row><cell cols="3">: Simulated error probabilities of four two-sample test procedures under four</cell></row><row><cell cols="3">different distributions. The type 1 error probabilities have been generated using</cell></row><row><cell cols="3">expectation µ = 1 in both samples, the type 2 error probabilities have been generated</cell></row><row><cell cols="2">using µ 1 = 1, µ 2 = 2 in the two samples.</cell><cell/></row><row><cell cols="3">Procedure Distribution Type 1 error prob. Type 2 error prob.</cell></row><row><cell>Welch's t</cell><cell>normal .0498</cell><cell>.0785</cell></row><row><cell>WMW</cell><cell>normal .0475</cell><cell>.0924</cell></row><row><cell>Combined</cell><cell>normal .0512</cell><cell>.0782</cell></row><row><cell>Permutation</cell><cell>normal .0487</cell><cell>.0778</cell></row><row><cell>Welch's t</cell><cell>t 3 .0453</cell><cell>.4127</cell></row><row><cell>WMW</cell><cell>t 3 .0482</cell><cell>.2585</cell></row><row><cell>Combined</cell><cell>t 3 .0515</cell><cell>.2700</cell></row><row><cell>Permutation</cell><cell>t 3 .0450</cell><cell>.4142</cell></row><row><cell cols="2">Welch's t exponential .0474</cell><cell>.3389</cell></row><row><cell cols="2">WMW exponential .0471</cell><cell>.4853</cell></row><row><cell cols="2">Combined exponential .0476</cell><cell>.4849</cell></row><row><cell cols="2">Permutation exponential .0455</cell><cell>.4472</cell></row><row><cell cols="2">Welch's t skew normal .0493</cell><cell>.0868</cell></row><row><cell cols="2">WMW skew normal .0481</cell><cell>.0778</cell></row><row><cell cols="2">Combined skew normal .0531</cell><cell>.0735</cell></row><row><cell cols="2">Permutation skew normal .0478</cell><cell>.0777</cell></row><row><cell cols="3">Depending on what deviation from normality seems more relevant in a given situation</cell></row><row><cell cols="3">(without knowing the true underlying distribution), and to what extent the weak anti-</cell></row><row><cell cols="3">conservativity of the combined procedure is a concern, a case could be made for any of</cell></row><row><cell>the methods.</cell><cell/><cell/></row><row><cell cols="3">Obviously results depend on the specific parameter values and sample sizes chosen, and</cell></row><row><cell cols="3">a comprehensive simulation study would vary these and possibly also look at situations</cell></row><row><cell cols="3">in which there are two different distributions in the two samples. One could also define</cell></row><row><cell cols="3">a more complex combined procedure involving an independence and homoscedasticity</cell></row><row><cell cols="3">test and a set of several AU tests accounting for different detected deviations from the</cell></row><row><cell>model assumptions.</cell><cell/><cell/></row><row><cell cols="3">Remark 1. Obviously, increasing the test size, it is possible to create tests with arbi-</cell></row><row><cell cols="3">trarily large power. Therefore achieving larger power may not be seen as worthwhile if</cell></row><row><cell cols="3">it comes to the price of a larger type 1 error probability. Then again, this may not be</cell></row><row><cell cols="3">seen as a problem as long as tests are still conservative, i.e., the type 1 error probability</cell></row><row><cell cols="3">is still not larger than the nominal level of the test. Three empirical type 1 error proba-</cell></row><row><cell cols="3">bilities for the combined procedure in Example 1 are larger than the nominal level 0.05,</cell></row><row><cell cols="3">but in two instances the difference is so small that it is only just about significant at 5%</cell></row><row><cell cols="3">level with 100,000 replicates. In reality any model assumption, e.g., independence, may</cell></row><row><cell cols="3">be violated, see Section 2, so that theoretical guarantees are never fully reliable. Given</cell></row><row><cell cols="3">that this is so, a user may find very weak anticonservativity acceptable if this leads to</cell></row><row><cell cols="2">substantially better power</cell><cell/></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head/><label/><figDesc><ref type="bibr" target="#b113">and Wells and Hintze (2007)</ref>, who recommend considering model assumptions pre-data, if possible using earlier data and pilot studies) are generally dismissive of preliminary MS testing. On the other hand, Spanos (2010) argued that it is not a problem at all, because the MS test and the main test "pose very different questions to data". The MS test tests whether the data "constitute a truly typical realisation of the stochastic mechanism described by the model". He argued that therefore model checking and model-based testing can be considered separately; model checking is about making sure that the model is "valid for the data"<ref type="bibr" target="#b100">(Spanos (2018)</ref>), and if it is, it is appropriate to go on with the model-based analysis. by the MS test. We do not think that the misspecification paradox automatically implies that combined procedures are invalid; as argued in Section 2, we do not believe that the model assumptions are true in reality anyway, and a combined procedure is worthwhile if it has good performance characteristics regarding the underlying scientific hypothesis, which may have formalisations regarding both the assumed model and the usually more general model employed by the AU test.If the distribution of the test statistic is independent of the outcome of the MS test, formally the misspecification paradox still holds, but it is statistically irrelevant. Conditioning on the result of the MS test will not affect the statistical characteristics of the MC test. An example for this is a MS test based on studentised residuals and a main test based on the minimal sufficient statistic of a normal distribution<ref type="bibr" target="#b99">(Spanos (2010)</ref>). More generally, it can be expected that if what the MS test does is at most very weakly stochastically connected to the main test (i.e., if in Spanos's terms they</figDesc><table/><note><p><p><p><p><p>The point of view taken here, as in</p><ref type="bibr" target="#b13">Chatfield (1995)</ref></p>;</p><ref type="bibr" target="#b47">Hennig (2007)</ref></p>, and elsewhere in the literature reviewed below, is different: We should analyse the characteristics of what is actually done. In case the model-based (MC) test is only applied if the model is not rejected, the behaviour of the MC test should be analysed conditionally on data not being rejected</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head/><label/><figDesc>to have little power for detecting distributions that cause problems for the t-test.<ref type="bibr" target="#b87">Rochon et al. (2012)</ref> investigated by simulation combined procedures based on preliminary normality testing both for both samples separately, and pooled residuals using a Shapiro-Wilk test of normality. The MC test was the two sample t-test, the AU test was the WMW test. Data were simulated from normal, exponential, and uniform distributions. In fact, for these distributions, the MC test was always better than the AU test, which makes a combined procedure superfluous; it reached acceptable performance characteristics, but inferior to the MC test. A truly heavy tailed distribution to challenge the MC test was not involved.<ref type="bibr" target="#b120">Zimmerman (2011)</ref> achieved good simulation results with an alternative approach, namely running both the two-sample t-test and the WMW test, choosing the twosample t-test in case the suitably standardised values of the test statistics are similar and the WMW test in case the p-values are very different. This seems to address the problem of detecting violations of normality better where it really matters. The tuning of this approach is somewhat less intuitive than for using a standard MS test.</figDesc><table/><note><p><p><p><p><p><p><p>presented a survey on comparing the two-sample t-test with the WMW test (involving further options such as Welch's t-test and a permutation t-test for exploring its distribution under H 0 ), concluding that the WMW test is superior where underlying distributions are heavy tailed or contain a certain amount of outliers; it is well known that the power of the t-test can break down under addition of a single outlier in the worst case, see</p><ref type="bibr" target="#b45">He et al. (1990)</ref></p>. Although Fay and Proschan did not explicitly investigate deciding between tand WMW-test by normality testing, they advise against it, stating that normality tests tend</p><ref type="bibr" target="#b59">Keselman et al. (2014)</ref> </p>recommended preliminary normality testing in the multi-sample problem (one-way ANOVA), taking multiple testing issues into account. They investigated the power of their multi-sample misspecification test scheme, but not of the resulting combined procedure.</p><ref type="bibr" target="#b63">Lantz et al. (2016)</ref> </p>investigated the use of a Shapiro-Wilk normality test (comparing various levels) to decide between running a standard ANOVA F-test and a nonparametric Kruskal-Wallis test under a number of normal and non-normal data generating processes. The corresponding combined procedure was recommended, because it displayed very slightly inflated type I error probabilities, but was close to the F-test where the F-test was better than Kruskal-Wallis, and close to Kruskal-Wallis where Kruskal-Wallis was better.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head/><label/><figDesc>n, with response Y = (y 1 , . . . , y n ) and explanatory variables X j = (x j1 , . . . , x jn ), j = 1, . . . , p. e 1 , . . . , e n are in the simplest case assumed i.i.d. normally distributed with mean 0 and equal variances. The regression model selection problem is the problem to select a subset of a given set of explanatory variables {X 1 , . . . , X p }. This can be framed as a model misspecification test problem, because a standard regression assumes that all variables that systematically influence the response variable are in the model (see, e.g., Sec. 6.9 of Gouveia Oliveira (2020)). If it is of interest, as main test problem, to test β j = 0 for a specific j, the MS test would be a test of null hypotheses β</figDesc><table/><note><p><p><p><p><p>k = 0 for one or more of the explanatory variables with k ̸ = j. The MC test would test β j = 0 in a model with X k removed, and the AU test would test β j = 0 in a model including X k . This problem was mentioned as second example in</p><ref type="bibr" target="#b4">Bancroft (1944)</ref></p>'s seminal paper on preliminary assumption testing.</p><ref type="bibr" target="#b100">Spanos (2018)</ref> </p>however argued that this is very different from MS testing in the earlier discussed settings, because if a model including β k is chosen based on a rejection of</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head/><label/><figDesc>Keep in mind that this is about power, i.e., we take the H 0 of the main test as violated for both P θ and Q. Assumption (I) means that the MC test has better power under P θ , (II) means that the AU test has better power under Q. Assumption (III) means that the MS test has some use, i.e., it has a certain (possibly weak) ability to distinguish between P θ and Q. All these are essential requirements for preliminary model assumption testing to make sense. Assumption (IV) though is very restrictive. It asks that rejection of the main null hypothesis by both main tests is independent of the decision made by the MS test. This is unrealistic in most situations, but it can be relaxed, as is done in Corollary 1 below, which requires only approximate independence. As emphasised earlier, approximate independence of the MS test and the main tests has also been found in other literature to be an important desirable feature of a combined test, and it should not surprise that a condition of this kind is required.</figDesc><table><row><cell/><cell>1.0</cell><cell/><cell/><cell/><cell/></row><row><cell/><cell/><cell>t-test</cell><cell/><cell/><cell/></row><row><cell/><cell/><cell cols="2">WMW-test</cell><cell/><cell/></row><row><cell/><cell>0.9</cell><cell cols="3">Combined procedure</cell><cell/></row><row><cell>power</cell><cell>0.8</cell><cell/><cell/><cell/><cell/></row><row><cell/><cell>0.7</cell><cell/><cell/><cell/><cell/></row><row><cell/><cell>0.6</cell><cell/><cell/><cell/><cell/></row><row><cell/><cell>0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1.0</cell></row><row><cell/><cell/><cell/><cell>λ</cell><cell/><cell/></row><row><cell cols="7">Figure 2: Power of combined procedure, MC (Welch's two-sample t-test), and AU test</cell></row><row><cell cols="6">(WMW-test) across different λs. The setup is from Example 1.</cell></row></table><note><p>IV) Both R M C and R AU are independent of R M S under both P θ and Q.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Should We Test the Model Assumptions?</head><p>We believe that the approach of Lemma 1 considering a random draw of either fulfilled or violated model assumptions could also help in more complex situations, for example, concerning different assumption violations, more than one MS test, and more than two main tests.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"/>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to Detect and Remove Temporal Autocorrelation in Vehicular Crash Data</title>
		<author>
			<persName><forename type="first">Azad</forename><surname>Abdulhafedh</surname></persName>
		</author>
		<idno type="DOI">10.4236/jtts.2017.72010</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Transportation Technologies</title>
		<title level="j" type="abbrev">JTTs</title>
		<idno type="ISSN">2160-0473</idno>
		<idno type="ISSNe">2160-0481</idno>
		<imprint>
			<biblScope unit="volume">07</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="133" to="147"/>
			<date type="published" when="2017">2017</date>
			<publisher>Scientific Research Publishing, Inc.</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The asymptotic behavior of tests for normal means based on a variance pre-test</title>
		<author>
			<persName><forename type="first">Willem</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieta</forename><forename type="middle">C</forename><surname>Boon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilbert</forename><forename type="middle">C M</forename><surname>Kallenberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0378-3758(99)00211-6</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<title level="j" type="abbrev">Journal of Statistical Planning and Inference</title>
		<idno type="ISSN">0378-3758</idno>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="57"/>
			<date type="published" when="2000-07">2000</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Size and power of pretest procedures</title>
		<author>
			<persName><forename type="first">Willem</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieta</forename><forename type="middle">C</forename><surname>Boon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilbert</forename><forename type="middle">C M</forename><surname>Kallenberg</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1016120369</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<title level="j" type="abbrev">Ann. Statist.</title>
		<idno type="ISSN">0090-5364</idno>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="195" to="214"/>
			<date type="published" when="2000-02-01">2000</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Nonexistence of Certain Statistical Procedures in Nonparametric Problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Bahadur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonard</forename><forename type="middle">J</forename><surname>Savage</surname></persName>
		</author>
		<idno type="DOI">10.1214/aoms/1177728077</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<title level="j" type="abbrev">Ann. Math. Statist.</title>
		<idno type="ISSN">0003-4851</idno>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1115" to="1122"/>
			<date type="published" when="1956-12">1956</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On Biases in Estimation Due to the Use of Preliminary Tests of Significance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Bancroft</surname></persName>
		</author>
		<idno type="DOI">10.1214/aoms/1177731284</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<title level="j" type="abbrev">Ann. Math. Statist.</title>
		<idno type="ISSN">0003-4851</idno>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="204"/>
			<date type="published" when="1944-06">1944</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analysis and Inference for Incompletely Specified Models Involving the Use of Preliminary Test(s) of Significance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Bancroft</surname></persName>
		</author>
		<idno type="DOI">10.2307/2528486</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<title level="j" type="abbrev">Biometrics</title>
		<idno type="ISSN">0006-341X</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">427</biblScope>
			<date type="published" when="1964-09">1964</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inference based on conditional specification: A note and a bibliography</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Bancroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="117" to="127"/>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Effect of Non-Normality on the &lt;i&gt;t&lt;/i&gt; Distribution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bartlett</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0305004100013311</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematical Proceedings of the Cambridge Philosophical Society</title>
		<title level="j" type="abbrev">Math. Proc. Camb. Phil. Soc.</title>
		<idno type="ISSN">0305-0041</idno>
		<idno type="ISSNe">1469-8064</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="231"/>
			<date type="published" when="1935-04">1935</date>
			<publisher>Cambridge University Press (CUP)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Valid post-selection inference</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Berk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1214/12-aos1077</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<title level="j" type="abbrev">Ann. Statist.</title>
		<idno type="ISSN">0090-5364</idno>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="802" to="837"/>
			<date type="published" when="2013-04-01">2013</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inference after checking multiple Bayesian models for data conflict and applications to mitigating the influence of rejected priors</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Bickel</surname></persName>
			<idno type="ORCID">0000-0002-9623-3946</idno>
		</author>
		<idno type="DOI">10.1016/j.ijar.2015.07.012</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<title level="j" type="abbrev">International Journal of Approximate Reasoning</title>
		<idno type="ISSN">0888-613X</idno>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="53" to="72"/>
			<date type="published" when="2015-11">2015</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sampling and Bayes' Inference in Scientific Modelling and Robustness</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<idno type="DOI">10.2307/2982063</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A (General)</title>
		<title level="j" type="abbrev">Journal of the Royal Statistical Society. Series A (General)</title>
		<idno type="ISSN">0035-9238</idno>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">383</biblScope>
			<date type="published" when="1980">1980</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The consequences of checking for zero‐inflation and overdispersion in the analysis of count data</title>
		<author>
			<persName><forename type="first">Harlan</forename><surname>Campbell</surname></persName>
			<idno type="ORCID">0000-0002-0959-1594</idno>
		</author>
		<idno type="DOI">10.1111/2041-210x.13559</idno>
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<title level="j" type="abbrev">Methods Ecol Evol</title>
		<idno type="ISSN">2041-210X</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="680"/>
			<date type="published" when="2021-02-12">2021</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The consequences of proportional hazards based model selection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.6021</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<title level="j" type="abbrev">Statist. Med.</title>
		<idno type="ISSN">0277-6715</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1042" to="1056"/>
			<date type="published" when="2014">2014</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Model Uncertainty, Data Mining and Statistical Inference</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Chatfield</surname></persName>
		</author>
		<idno type="DOI">10.2307/2983440</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A (Statistics in Society)</title>
		<title level="j" type="abbrev">Journal of the Royal Statistical Society. Series A (Statistics in Society)</title>
		<idno type="ISSN">0964-1998</idno>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">419</biblScope>
			<date type="published" when="1995">1995</date>
			<publisher>Oxford University Press (OUP)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Principles of Statistical Inference</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<idno type="DOI">10.1017/cbo9780511813559</idno>
		<imprint>
			<date type="published" when="2006-08-10">2006</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">RELAXING ASSUMPTIONS IN THE ONE SAMPLE &lt;i&gt;t&lt;/i&gt;‐TEST</title>
		<author>
			<persName><forename type="first">Noel</forename><surname>Cressie</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-842x.1980.tb01161.x</idno>
	</analytic>
	<monogr>
		<title level="j">Australian Journal of Statistics</title>
		<title level="j" type="abbrev">Australian Journal of Statistics</title>
		<idno type="ISSN">0004-9581</idno>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="153"/>
			<date type="published" when="1980-06">1980</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Data Analysis and Approximate Models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Davies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<pubPlace>Boca Raton FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Theory of Probability</title>
		<author>
			<persName><forename type="first">B</forename><surname>De Finetti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">One-Sided Inference about Functionals of a Density</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1176351045</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<title level="j" type="abbrev">Ann. Statist.</title>
		<idno type="ISSN">0090-5364</idno>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1390" to="1420"/>
			<date type="published" when="1988-12-01">1988</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Statistics for Research</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dowdy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wearden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chilko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Assessment and Propagation of Model Uncertainty</title>
		<author>
			<persName><forename type="first">David</forename><surname>Draper</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2517-6161.1995.tb02015.x</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<idno type="ISSN">1369-7412</idno>
		<idno type="ISSNe">1467-9868</idno>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="70"/>
			<date type="published" when="1995-01-01">1995</date>
			<publisher>Oxford University Press (OUP)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Goodness of fit and parameter estimation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Easterling</surname></persName>
		</author>
		<idno type="DOI">10.1080/00401706.1976.10489394</idno>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="9"/>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The effect of preliminary normality goodness of fit tests on subsequent inference.</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Easterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1080/00949657808810243</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Computation and Simulation</title>
		<title level="j" type="abbrev">Journal of Statistical Computation and Simulation</title>
		<idno type="ISSN">0094-9655</idno>
		<idno type="ISSNe">1563-5163</idno>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11"/>
			<date type="published" when="1978-10">1978</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Estimation and Accuracy After Model Selection</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.2013.823775</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<title level="j" type="abbrev">Journal of the American Statistical Association</title>
		<idno type="ISSN">0162-1459</idno>
		<idno type="ISSNe">1537-274X</idno>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">507</biblScope>
			<biblScope unit="page" from="991" to="1007"/>
			<date type="published" when="2014-07-03">2014</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comprehensive study of tests for normality and symmetry: extending the Spiegelhalter test</title>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">J</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrina</forename><surname>Rogers-Stewart</surname></persName>
		</author>
		<idno type="DOI">10.1080/10629360500109023</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Computation and Simulation</title>
		<title level="j" type="abbrev">Journal of Statistical Computation and Simulation</title>
		<idno type="ISSN">0094-9655</idno>
		<idno type="ISSNe">1563-5163</idno>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="803" to="816"/>
			<date type="published" when="2006-09">2006</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wilcoxon-Mann-Whitney or t-test? On assumptions for hypothesis tests and multiple interpretations of decision rules</title>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">P</forename><surname>Fay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Proschan</surname></persName>
		</author>
		<idno type="DOI">10.1214/09-ss051</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics Surveys</title>
		<title level="j" type="abbrev">Statist. Surv.</title>
		<idno type="ISSN">1935-7516</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">none</biblScope>
			<biblScope unit="page" from="1" to="39"/>
			<date type="published" when="2010-01-01">2010</date>
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the Cost of Approximate Specification in Simultaneous Equation Estimation</title>
		<author>
			<persName><forename type="first">Franklin</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.2307/1909286</idno>
		<idno>29:2&lt;139:OTCOAS&gt;2.0.CO;2-X</idno>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<title level="j" type="abbrev">Econometrica</title>
		<idno type="ISSN">0012-9682</idno>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="1961-04">1961. 196104</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the mathematical foundations of theoretical statistics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsta.1922.0009</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</title>
		<title level="j" type="abbrev">Phil. Trans. R. Soc. Lond. A</title>
		<idno type="ISSN">0264-3952</idno>
		<idno type="ISSNe">2053-9258</idno>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="issue">594-604</biblScope>
			<biblScope unit="page" from="309" to="368"/>
			<date type="published" when="1922-01">1922</date>
			<publisher>The Royal Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The performance of the two‐stage analysis of two‐treatment, two‐period crossover trials</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Freeman</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.4780081202</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<title level="j" type="abbrev">Statistics in Medicine</title>
		<idno type="ISSN">0277-6715</idno>
		<idno type="ISSNe">1097-0258</idno>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1421" to="1432"/>
			<date type="published" when="1989-12">1989</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Impact of UVA exposure on psychological parameters and circulating serotonin and melatonin</title>
		<author>
			<persName><forename type="first">Thilo</forename><surname>Gambichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirjana</forename><surname>Vojvodic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Falk</forename><forename type="middle">G</forename><surname>Bechara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirsten</forename><surname>Sauermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Altmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Hoffmann</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-5945-2-6</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Dermatology</title>
		<title level="j" type="abbrev">BMC Dermatol</title>
		<idno type="ISSNe">1471-5945</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="174"/>
			<date type="published" when="2002-04-12">2002</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Guidelines for the Content of Statistical Analysis Plans in Clinical Trials</title>
		<author>
			<persName><forename type="first">Carrol</forename><surname>Gamble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashma</forename><surname>Krishan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Stocken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steff</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edmund</forename><surname>Juszczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Doré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paula</forename><forename type="middle">R</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pilar</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Berlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Senn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yolanda</forename><surname>Barbachano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Loder</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2017.18556</idno>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<title level="j" type="abbrev">JAMA</title>
		<idno type="ISSN">0098-7484</idno>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">2337</biblScope>
			<date type="published" when="2017-12-19">2017</date>
			<publisher>American Medical Association (AMA)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Use of a preliminary test in comparing two sample means</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Gans</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610918108812201</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics - Simulation and Computation</title>
		<title level="j" type="abbrev">Communications in Statistics - Simulation and Computation</title>
		<idno type="ISSN">0361-0918</idno>
		<idno type="ISSNe">1532-4141</idno>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="174"/>
			<date type="published" when="1981-01">1981</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Beyond Subjective and Objective in Statistics</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.1111/rssa.12276</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series A: Statistics in Society</title>
		<idno type="ISSN">0964-1998</idno>
		<idno type="ISSNe">1467-985X</idno>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="967" to="1033"/>
			<date type="published" when="2017-08-06">2017</date>
			<publisher>Oxford University Press (OUP)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Statistical Crisis in Science</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Loken</surname></persName>
		</author>
		<idno type="DOI">10.1515/9781400873371-028</idno>
	</analytic>
	<monogr>
		<title level="m">The Best Writing on Mathematics 2015</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="305" to="318"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Philosophy and the Practice of Bayesian Statistics in the Social Sciences</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosma</forename><forename type="middle">Rohilla</forename><surname>Shalizi</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780195392753.013.0011</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="8" to="38"/>
			<date type="published" when="2013">2013</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PRE‐TEST ESTIMATION AND TESTING IN ECONOMETRICS: RECENT DEVELOPMENTS</title>
		<author>
			<persName><forename type="first">Judith</forename><forename type="middle">A</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E A</forename><surname>Giles</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-6419.1993.tb00163.x</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Surveys</title>
		<title level="j" type="abbrev">Journal of Economic Surveys</title>
		<idno type="ISSN">0950-0804</idno>
		<idno type="ISSNe">1467-6419</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="197"/>
			<date type="published" when="1993-06">1993</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Misspecification Tests in Econometrics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Godfrey</surname></persName>
		</author>
		<idno type="DOI">10.1017/ccol0521266165</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Misspecification tests and their uses in econometrics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Godfrey</surname></persName>
		</author>
		<idno type="DOI">10.1016/0378-3758(95)00039-9</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<title level="j" type="abbrev">Journal of Statistical Planning and Inference</title>
		<idno type="ISSN">0378-3758</idno>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="260"/>
			<date type="published" when="1996-01">1996</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Biostatistics Decoded</title>
		<author>
			<persName><forename type="first">Gouveia</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.1002/9781119584254</idno>
		<imprint>
			<date type="published" when="2020-09-04">2020</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The Two-Period Change-Over Design and Its Use in Clinical Trials</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Grizzle</surname></persName>
		</author>
		<idno type="DOI">10.2307/2528104</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<title level="j" type="abbrev">Biometrics</title>
		<idno type="ISSN">0006-341X</idno>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">467</biblScope>
			<date type="published" when="1967">1967. 1974</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
	<note>Biometrics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Upper bound for the size of a test procedure using preliminary tests of significance</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Indian Statistical Association</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="26" to="29"/>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Testing Equality of Means after a Preliminary test of Equality of Variances</title>
		<author>
			<persName><forename type="first">John</forename><surname>Gurland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">S</forename><surname>Mccullough</surname></persName>
		</author>
		<idno type="DOI">10.2307/2333975</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<title level="j" type="abbrev">Biometrika</title>
		<idno type="ISSN">0006-3444</idno>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page">403</biblScope>
			<date type="published" when="1962-12">1962</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Robust Statistics</title>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">R</forename><surname>Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elvezio</forename><forename type="middle">M</forename><surname>Ronchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><forename type="middle">A</forename><surname>Stahel</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781118186435</idno>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Statistical Expert Systems: Design</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
		<idno type="DOI">10.2307/2987739</idno>
	</analytic>
	<monogr>
		<title level="j">The Statistician</title>
		<title level="j" type="abbrev">The Statistician</title>
		<idno type="ISSN">0039-0526</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">351</biblScope>
			<date type="published" when="1984-12">1984</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sustained Improvement of Negative Self-Schema After a Single Ketamine Infusion: An Open-Label Study</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samir</forename><surname>Suker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Schoretsanitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoan</forename><surname>Mihov</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2020.00687</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<title level="j" type="abbrev">Front. Neurosci.</title>
		<idno type="ISSNe">1662-453X</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">687</biblScope>
			<date type="published" when="2020-07-01">2020</date>
			<publisher>Frontiers Media SA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Breakdown Robustness of Tests</title>
		<author>
			<persName><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">G</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">L</forename><surname>Portnoy</surname></persName>
		</author>
		<idno type="DOI">10.2307/2289782</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<title level="j" type="abbrev">Journal of the American Statistical Association</title>
		<idno type="ISSN">0162-1459</idno>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">410</biblScope>
			<biblScope unit="page">446</biblScope>
			<date type="published" when="1990-06">1990</date>
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Empirical Model Discovery and Theory Evaluation</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Hendry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jurgen</forename><forename type="middle">A</forename><surname>Doornik</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/9780262028356.001.0001</idno>
		<imprint>
			<date type="published" when="2014-07-03">2014</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Falsification of Propensity Models by Statistical Tests and the Goodness-of-Fit Paradox</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.1093/philmat/nkm001</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophia Mathematica</title>
		<title level="j" type="abbrev">Philosophia Mathematica</title>
		<idno type="ISSN">0031-8019</idno>
		<idno type="ISSNe">1744-6406</idno>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="166" to="192"/>
			<date type="published" when="2007-03-23">2007</date>
			<publisher>Oxford University Press (OUP)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mathematical Models and Reality: A Constructivist Perspective</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10699-009-9167-x</idno>
	</analytic>
	<monogr>
		<title level="j">Foundations of Science</title>
		<title level="j" type="abbrev">Found Sci</title>
		<idno type="ISSN">1233-1821</idno>
		<idno type="ISSNe">1572-8471</idno>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="48"/>
			<date type="published" when="2010">2010</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Parameters not empirically identifiable or distinguishable, including correlation between Gaussian observations</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Hennig</surname></persName>
			<idno type="ORCID">0000-0003-1550-5637</idno>
		</author>
		<idno type="DOI">10.1007/s00362-023-01414-3</idno>
		<idno>1007/ s00362-023-01414-3</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Papers</title>
		<title level="j" type="abbrev">Stat Papers</title>
		<idno type="ISSN">0932-5026</idno>
		<idno type="ISSNe">1613-9798</idno>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="771" to="794"/>
			<date type="published" when="2023-03-05">2023</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Are assumptions of well-known statistical techniques checked, and why (not)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hoekstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00137</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Nonparametric statistics: Rank-based methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hollander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sethuraman</surname></persName>
		</author>
		<idno type="DOI">10.1016/B0-08-043076-7/00479-4</idno>
	</analytic>
	<monogr>
		<title level="m">International Encyclopedia of the Social and Behavioral Sciences</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Smelser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Baltes</surname></persName>
		</editor>
		<meeting><address><addrLine>Pergamon, Oxford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="10673" to="10680"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A randomized, double-blind, placebocontrolled trial of pramipexole, a dopamine agonist, in patients with fibromyalgia receiving concomitant medications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1002/art.21191</idno>
	</analytic>
	<monogr>
		<title level="j">Arthritis &amp; Rheumatism</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="2495" to="2505"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Contribution to the theory of "Student's" t-test as applied to the problem of two samples</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Hsu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4684-9324-5_8</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Research Memoirs</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="24"/>
			<date type="published" when="1938">1938</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The effect of limitations on the number of criterion score values on the significance level of the F -test</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Feldt</surname></persName>
		</author>
		<idno type="DOI">10.2307/1162248</idno>
	</analytic>
	<monogr>
		<title level="j">American Educational Research Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="515" to="527"/>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bias in randomised factorial trials</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kahan</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.5869</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4540" to="4549"/>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Ten simple rules for effective statistical practice</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Caffo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davidian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Reid</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1004961</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">1004961</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Statistical practices of educational researchers: An analysis of their ANOVA, MANOVA, and ANCOVA analyses</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Huberty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Olejnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Kovalchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Lowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Petoskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Levin</surname></persName>
		</author>
		<idno type="DOI">10.2307/1170601</idno>
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="350" to="386"/>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Preliminary testing for normality: Is this a good practice</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Othman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wilcox</surname></persName>
		</author>
		<idno type="DOI">10.22237/jmasm/1383278460</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Modern Applied Statistical Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2" to="19"/>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Testing for normality in the multi-group problem: Is this a good practice</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Othman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wilcox</surname></persName>
		</author>
		<idno type="DOI">10.11138/CDERM/2014.2.1.029</idno>
	</analytic>
	<monogr>
		<title level="j">Clinical Dermatology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="29" to="43"/>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Comparison of several univariate normality tests regarding type I error rate and power of the test in simulation based small samples</title>
		<author>
			<persName><forename type="first">S</forename><surname>Keskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Science Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="296" to="300"/>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Autocorrelation pre-testing in the linear model: Estimation, testing and prediction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E A</forename><surname>Giles</surname></persName>
		</author>
		<idno>0.1016/0304-4076(84)90035-6</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="35" to="48"/>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Heart rate variability, multifractal multiscale patterns and their assessment criteria</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kokosinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gieraltowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Zebrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Orlowska-Baranowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baranowski</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6579/aae86d</idno>
	</analytic>
	<monogr>
		<title level="j">Physiological Measurement</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">114010</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Preliminary tests of normality when comparing three independent samples</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manfredsson</surname></persName>
		</author>
		<idno type="DOI">10.22237/JMASM/1478002140</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Modern Applied Statistical Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="135" to="148"/>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Model selection and inference: Fact and fiction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pötscher</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0266466605050036</idno>
	</analytic>
	<monogr>
		<title level="j">Econometric Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="21" to="59"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">On various confidence intervals post-model-selection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pötscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ewald</surname></persName>
		</author>
		<idno type="DOI">10.1214/14-STS507</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="216" to="227"/>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Testing Statistical Hypotheses</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Romano</surname></persName>
		</author>
		<idno type="DOI">10.1007/0-387-27605-X</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Robust tests for equality of variances</title>
		<author>
			<persName><forename type="first">H</forename><surname>Levene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Olkin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Ghurye</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Hoeffding</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Madow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mann</surname></persName>
		</editor>
		<meeting><address><addrLine>Redwood City CA</addrLine></address></meeting>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="1960">1960</date>
			<biblScope unit="page" from="278" to="292"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Conditions for the effectiveness of a preliminary test of variance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Markowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Markowski</surname></persName>
		</author>
		<idno type="DOI">10.2307/2684360</idno>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="131" to="136"/>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Testing categorized bivariate normality with two-stage polychoric correlation estimates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maydeu-Olivares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Forero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gallardo-Pujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Renom</surname></persName>
		</author>
		<idno type="DOI">10.1027/1614-2241.5.4.131</idno>
	</analytic>
	<monogr>
		<title level="j">Methodology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="131" to="136"/>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Statistical Inference as Severe Testing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Mayo</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781107286184</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Misspecification testing: A comprehensive approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mcguirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Driscoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Alwang</surname></persName>
		</author>
		<idno type="DOI">10.2307/1243992</idno>
		<ptr target="http://www.jstor.org/stable/1243992"/>
	</analytic>
	<monogr>
		<title level="j">American Journal of Agricultural Economics</title>
		<idno type="ISSN">00029092, 14678276</idno>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1044" to="1055"/>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Type I error rate and power of three normality tests</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pala</surname></persName>
		</author>
		<idno type="DOI">10.3923/itj.2003.135.139</idno>
	</analytic>
	<monogr>
		<title level="j">Pakistan Journal of Information and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="135" to="139"/>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Alternatives to F -test in one way ANOVA in case of heterogeneity of variances (a simulation study)</title>
		<author>
			<persName><forename type="first">K</forename><surname>Moder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Testing and Assessment Modeling</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="343" to="353"/>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Homogeneity of variance in the two-sample means test</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.2307/2684403</idno>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="19" to="21"/>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">The two-sample t test versus Satterthwaite's approximate f test</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Watts</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610928908830135</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="3963" to="3975"/>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A Monte Carlo study comparing various two sample tests for differences in means</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Neave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
		<idno type="DOI">10.2307/1267105</idno>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="509" to="522"/>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</author>
		<idno type="DOI">10.22004/ag.econ.327287</idno>
		<title level="m">Lectures and Conferences on Mathematical Statistics and Probability</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<publisher>U.S. Department of Agriculture</publisher>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Statistical methods and errors in family medicine articles between 2010 and 2014-Suez Canal University, Egypt: A cross-sectional study</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nour-Eldein</surname></persName>
		</author>
		<idno type="DOI">10.4103/2249-4863.184619</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Family Medicine and Primary Care</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="24" to="33"/>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Testing linear hypothesis on regression coefficients after a pre-test for disturbance variance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ohtani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Toyoda</surname></persName>
		</author>
		<idno type="DOI">10.1016/0165-1765(85)90138-7</idno>
	</analytic>
	<monogr>
		<title level="j">Economics Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="111" to="114"/>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1080/14786440009463897</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="157" to="175"/>
			<date type="published" when="1900">1900</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Significance tests which may be applied to samples from any populations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J G</forename><surname>Pitman</surname></persName>
		</author>
		<idno type="DOI">10.2307/2984124</idno>
		<ptr target="http://www.jstor.org/stable/2984124"/>
	</analytic>
	<monogr>
		<title level="j">Supplement to the Journal of the Royal Statistical Society</title>
		<idno type="ISSN">14666162</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="130"/>
			<date type="published" when="1937">1937</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Robustness of the two-sample t-test under violations of the homogeneity of variance assumptions</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">O</forename><surname>Posten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Owen</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610928208828221</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics: Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="109" to="126"/>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">The robustness of parametric statistical methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Guiard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology Science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="175" to="208"/>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The two-sample t test: pretesting its assumptions does not pay off</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Kubinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moder</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00362-009-0224-x</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Papers</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="219" to="231"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A review of preliminary test-based statistical methods for the benefit of Six Sigma quality practitioners</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ravichandran</surname></persName>
		</author>
		<idno type="DOI">10.1007/S00362-010-0359-9</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Papers</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="531" to="547"/>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Razali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Wah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Modeling and Analytics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="21" to="33"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">To test or not to test: Preliminary assessment of normality when comparing two independent samples</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rochon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gondan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kieser</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2288-12-81</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="81" to="91"/>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A closer look at the effect of preliminary goodnessof-fit testing for normality for the one-sample t-test</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rochon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kieser</surname></persName>
		</author>
		<idno type="DOI">10.1348/2044-8317.002003</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="410" to="426"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Theory of preliminary test and Stein-type estimation with applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M E</forename><surname>Saleh</surname></persName>
		</author>
		<idno type="DOI">10.1002/0471773751</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Asymptotic properties of tests of hypothesis following a preliminary test</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M E</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Sen</surname></persName>
		</author>
		<idno type="DOI">10.1524/strm.1983.1.45.455</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics and Risk Modeling</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="478"/>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">An approximate distribution of estimates of variance components</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Satterthwaite</surname></persName>
		</author>
		<idno type="DOI">10.2307/3002019</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrics Bulletin</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="110" to="114"/>
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Practical solutions of the Behrens-Fisher problem</title>
		<author>
			<persName><forename type="first">H</forename><surname>Scheffé</surname></persName>
		</author>
		<idno type="DOI">10.2307/2284332</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1501" to="1508"/>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Linear regression and the normality assumption</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jclinepi.2017.12.006</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Epidemiology</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="146" to="151"/>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Preliminary testing for normality: some statistical aspects of a common concept</title>
		<author>
			<persName><forename type="first">V</forename><surname>Schoder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Himmelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Wilhelm</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1365-2230.2006.02206.x</idno>
	</analytic>
	<monogr>
		<title level="j">Clinical and Experimental Dermatology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="757" to="761"/>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Preliminary goodness-of-fit tests for normality do not validate the one-sample student t</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Schucany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K T</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610920600853308</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics -Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2275" to="2286"/>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Diagnostics for assumptions in moderate to large simple clinical trials: do they really help?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Shuster</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.2175</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2431" to="2438"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Automated data analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spisic</surname></persName>
		</author>
		<idno type="DOI">10.1002/wics.1318</idno>
	</analytic>
	<monogr>
		<title level="j">WIREs Computational Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="359" to="366"/>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Probability Theory and Statistical Inference: Econometric Modeling with Observational Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spanos</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511754081</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Akaike-type criteria and the reliability of inference: Model selection versus statistical model specification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spanos</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jeconom.2010.01.011</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="204" to="220"/>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Mis-specification testing in retrospect</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spanos</surname></persName>
		</author>
		<idno type="DOI">10.1111/joes.12200</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Surveys</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="541" to="577"/>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Reporting quality of statistics in Indian journals: Analysis of articles over a period of two years</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gowri</surname></persName>
		</author>
		<idno type="DOI">10.4103/2320-0057.156015</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Scientometric Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="10" to="13"/>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">The use of statistics in medical research: A comparison of The New England Journal of Medicine and Nature Medicine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Strasak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marinell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ulmer</surname></persName>
		</author>
		<idno type="DOI">10.1198/000313007X170242</idno>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="47" to="55"/>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">The use of statistics in medical research: A comparison of Wiener Klinische Wochenschrift and Wiener Medizinische Wochenschrift</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Strasak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marinell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ulmer</surname></persName>
		</author>
		<idno type="DOI">10.17713/ajs.v36i2.327</idno>
	</analytic>
	<monogr>
		<title level="j">Austrian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="141" to="152"/>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Why checking model assumptions using null hypothesis significance tests does not suffice: A plea for plausibility</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tijmstra</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1447-4</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="548" to="559"/>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Testing equality between sets of coefficients after a preliminary test for equality of disturbance variances in two linear regressions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Toyoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ohtani</surname></persName>
		</author>
		<idno type="DOI">10.1016/0304-4076(86)90056-4</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="67" to="80"/>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">More honest foundations for data analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0378-3758(96)00032-8</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="21" to="28"/>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Asymptotic Statistics</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Van Der Vaart</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511802256</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Pre-registration in social psychology -a discussion and suggested template</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Van't Veer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Giner-Sorolla</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2016.03.004</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="2" to="12"/>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">The ASA statement on p-values: Context, process, and purpose</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wasserstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Lazar</surname></persName>
		</author>
		<idno type="DOI">10.1080/00031305.2016.1154108</idno>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="133"/>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Approximate models and robust decisions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1214/16-STS592</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="489"/>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">The significance of the difference between two means when the population variances are unequal</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Welch</surname></persName>
		</author>
		<idno type="DOI">10.2307/2332010</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="350" to="362"/>
			<date type="published" when="1938">1938</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The generalisation of Student's problem when several different population variances are involved</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Welch</surname></persName>
		</author>
		<idno type="DOI">10.2307/2332510</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="28" to="35"/>
			<date type="published" when="1947">1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Dealing with assumptions underlying statistical tests</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hintze</surname></persName>
		</author>
		<idno type="DOI">10.1002/pits.20241</idno>
	</analytic>
	<monogr>
		<title level="j">Psychology in the Schools</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="495" to="502"/>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">A plea for more general tests than those for location only: Further considerations on Rasch &amp; Guiard's 'the robustness of parametric statistical methods</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wiedermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alexandrowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology Science</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="2" to="12"/>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Dealing with distributional assumptions in preregistered research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Albers</surname></persName>
		</author>
		<idno type="DOI">10.15626/MP.2018.1592</idno>
	</analytic>
	<monogr>
		<title level="j">Meta-Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="15"/>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Misuse of statistical methods in 10 leading Chinese medical journals in 1998 and 2008</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1100/2011/139494</idno>
	</analytic>
	<monogr>
		<title level="j">The Scientific World Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2106" to="2114"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Design assessment in virtual and mixed reality environments: Comparison of novices and experts</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hartless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tesei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gunji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>London</surname></persName>
		</author>
		<idno type="DOI">10.1061/(ASCE)CO.1943-7862.0001683</idno>
		<idno>)CO.1943-7862.0001683</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Construction Engineering and Management</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page">4019049</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>ASCE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Post-model-selection inference in linear regression models: An integrated review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Asgharian</surname></persName>
		</author>
		<idno type="DOI">10.1214/22-SS135</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics Surveys</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="86" to="136"/>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Two separate effects of variance heterogeneity on the validity and power of significance tests of location</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zimmerman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.stamet.2005.10.002</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="351" to="374"/>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A simple and effective decision rule for choosing a significance test to protect against non-normality</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zimmerman</surname></persName>
		</author>
		<idno type="DOI">10.1348/000711010X524739</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="388" to="409"/>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Consequences of choosing samples in hypothesis testing to ensure homogeneity of variance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zimmerman</surname></persName>
		</author>
		<idno type="DOI">10.1111/bmsp.12001</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1" to="29"/>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>